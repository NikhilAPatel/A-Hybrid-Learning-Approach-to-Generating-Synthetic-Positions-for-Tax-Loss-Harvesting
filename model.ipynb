{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A Hybrid Learning Approach to Synthetic Position Construction for Tax Loss Harvesting"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generation of Synthetic Positions Using Hybrid Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "import statsmodels.api as sm\n",
    "import operator\n",
    "from deprecated import deprecated\n",
    "\n",
    "corr_matrix_file_path = \"pickles/corr_matrix.obj\"\n",
    "x_labels_file_path = \"pickles/X_labels.obj\"\n",
    "sptm_comp_file_path = \"pickles/sptm_composition.obj\"\n",
    "sptm_price_file_path = \"pickles/sptm_price.obj\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Composition data from pickle\n",
    "sptm_comp_file = open(sptm_comp_file_path, 'rb')\n",
    "sptm_composition = pickle.load(sptm_comp_file)\n",
    "sptm_comp_file.close()\n",
    "\n",
    "# Price history downloaded from Yahoo Finance and stored in pickle\n",
    "sptm_price_file = open(sptm_price_file_path, 'rb')\n",
    "sptm_price_history = pickle.load(sptm_price_file)\n",
    "sptm_price_file.close()\n",
    "\n",
    "all_tickers = sptm_composition.keys()\n",
    "\n",
    "# Gets a list of all valid trading dates\n",
    "all_dates = sptm_price_history[list(all_tickers)[0]].axes[0].values\n",
    "dates = pd.DatetimeIndex(data=all_dates)\n",
    "current_date = all_dates[0]\n",
    "\n",
    "# 80/20 Test/Train Split\n",
    "# Data Range: 2015-01-02 - 2020-08-10\n",
    "# Testing Range: 2020-08-11 - 2021-12-31\n",
    "train_start_date = 0\n",
    "train_end_date = 1410\n",
    "test_start_date = 1411\n",
    "test_end_date = 1762\n",
    "\n",
    "# Choose how many days should be used to validate the hyperparameters\n",
    "num_validation_days = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding Highly Correlated Stocks\n",
    "#### Use the *do_corr_matrix_regen* variable to tell the code to generate the correlation matrix, else it will load it from a pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "num_stocks = len(all_tickers)\n",
    "\n",
    "\n",
    "@deprecated(reason=\"Switched to generating singular correlation lists on the fly\")\n",
    "def regenerate_corr_matrix(end_date, recent_days):\n",
    "    \"\"\"Calculates the correlation between every stock's percent time series\n",
    "    :param end_date: The last date for which data should be used to generate the correlation matrix\n",
    "    :param recent_days: How many days of price history should be used to calculate the correlation matrix\n",
    "    \"\"\"\n",
    "    x_vars = []\n",
    "    x_labels = []\n",
    "\n",
    "    for ticker in all_tickers:\n",
    "        x_vars.append(sptm_price_history[ticker].Close.pct_change().iloc[end_date - recent_days:end_date])\n",
    "        x_labels.append(ticker)\n",
    "\n",
    "    correlation_matrix = [[0 for _ in range(0, num_stocks)] for _ in range(0, num_stocks)]\n",
    "\n",
    "    for l in range(0, num_stocks):\n",
    "        for m in range(0, num_stocks):\n",
    "            correlation_matrix[l][m] = x_vars[l].corr(x_vars[m])\n",
    "    correlation_matrix = pd.DataFrame(correlation_matrix, columns=x_labels[0:num_stocks])\n",
    "\n",
    "    correlation_matrix_file = open(corr_matrix_file_path, 'wb')\n",
    "    pickle.dump(correlation_matrix, correlation_matrix_file)\n",
    "    correlation_matrix_file.close()\n",
    "\n",
    "    x_labels_file = open(x_labels_file_path, 'wb')\n",
    "    pickle.dump(x_labels, x_labels_file)\n",
    "    x_labels_file.close()\n",
    "\n",
    "\n",
    "@deprecated(reason=\"Switched to generating singular correlation lists on the fly\")\n",
    "def load_corr_matrix():\n",
    "    \"\"\"Loads correlation matrix and labels from pickles\n",
    "    :returns: [correlation_matrix, x_labels]\n",
    "    \"\"\"\n",
    "    # Covariance Matrix from pickle\n",
    "    corr_matrix_file = open(corr_matrix_file_path, 'rb')\n",
    "    correlation_matrix = pickle.load(corr_matrix_file)\n",
    "    corr_matrix_file.close()\n",
    "\n",
    "    # X_Labels from pickle\n",
    "    x_labels_file = open(x_labels_file_path, 'rb')\n",
    "    x_labels = pickle.load(x_labels_file)\n",
    "    x_labels_file.close()\n",
    "\n",
    "    return correlation_matrix, x_labels\n",
    "\n",
    "\n",
    "def corr_list_for_single_stock(ticker, end_date, recent_days):\n",
    "    x_labels = []\n",
    "\n",
    "    ticker_price_history = sptm_price_history[ticker].Close.pct_change().iloc[end_date - recent_days:end_date]\n",
    "\n",
    "    for tickers in sptm_price_history.keys():\n",
    "        x_labels.append(tickers)\n",
    "\n",
    "    correlation_matrix = {}\n",
    "\n",
    "    for l in range(0, len(x_labels)):\n",
    "        correlation_matrix[x_labels[l]] = ticker_price_history.corr(\n",
    "            sptm_price_history[x_labels[l]].Close.pct_change().iloc[end_date - recent_days:end_date])\n",
    "    correlation_matrix = dict(sorted(correlation_matrix.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "    return correlation_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def filter_substantially_similar_securities(ticker, series, additional_stocks=None):\n",
    "    \"\"\"Filters out the stocks you cannot buy because of a wash sale\n",
    "    :param series: The series of correlated stocks that should be filtered\n",
    "    :param ticker: Ticker to filter out securities for\n",
    "    :param additional_stocks: Any additional stocks you want to filter out (default = None)\n",
    "    \"\"\"\n",
    "    if additional_stocks is None:\n",
    "        additional_stocks = []\n",
    "\n",
    "    # Handles Google having both GOOG and GOOGL in the dataset\n",
    "    if ticker == \"GOOG\" or ticker:\n",
    "        additional_stocks.append(\"GOOG\")\n",
    "        additional_stocks.append(\"GOOGL\")\n",
    "\n",
    "    additional_stocks.append(ticker)\n",
    "\n",
    "    for remove_stock in additional_stocks:\n",
    "        # for r_stock in remove_stock:\n",
    "        if remove_stock in series:\n",
    "            series.pop(series.index(remove_stock))\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def find_top_correlated_stocks(correlation_list, ticker, n):\n",
    "    \"\"\"Finds the top n stocks correlated with a given stock\n",
    "    :param correlation_list: The correlation list to get the top correlated stocks from\n",
    "    :param n: the number of correlated stocks to return\n",
    "    :param ticker: The ticker for which correlated stocks should be found\n",
    "    :returns: A list (sorted by most correlation) of correlated stocks\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_correlations = filter_substantially_similar_securities(ticker, list(correlation_list.keys()))\n",
    "\n",
    "    return filtered_correlations[:n]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Principle Component Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_price_histories_dataframe(stocks, target_stock, end_date, recent_days):\n",
    "    \"\"\"Compiles a DataFrame with the price histories of the specified stocks\n",
    "    :param target_stock: The stock for which the dataset should be created\n",
    "    :param stocks: The stocks to include in the DataFrame\n",
    "    :param end_date: The last date for which data should be used to get the price history\n",
    "    :param recent_days: How many days of price history should be fetched\n",
    "    :returns: (Features DataFrame, Target DataFrame)\"\"\"\n",
    "    d = {}\n",
    "    for correlated_stock in stocks:\n",
    "        d[correlated_stock] = sptm_price_history[correlated_stock].Close.values[end_date - recent_days:end_date]\n",
    "    target = pd.DataFrame(\n",
    "        {target_stock: sptm_price_history[target_stock].Close.values[end_date - recent_days:end_date]})\n",
    "    return pd.DataFrame(data=d), target\n",
    "\n",
    "\n",
    "def get_datasets(correlation_list, target_stock, n, end_date, recent_days):\n",
    "    \"\"\"Compiles the necessary datasets for PCA. One with the price history of the features, and one with the price history of the target\n",
    "    :param correlation_list: The correlation list to get the top correlated stocks from\n",
    "    :param target_stock: The stock for which the dataset should be created\n",
    "    :param n: the number of datasets to get\n",
    "    :param end_date: The last date for which data should be used to get the price history\n",
    "    :param recent_days: How many days of price history should be fetched\n",
    "    :returns: (x, y) where x and y are DataFrames\n",
    "    \"\"\"\n",
    "    corr_stocks = find_top_correlated_stocks(correlation_list, target_stock, n)\n",
    "    return get_price_histories_dataframe(corr_stocks, target_stock, end_date, recent_days)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def predict_portfolio(pred_stock, n_components, n_days, end_date, n_stocks, is_sparse):\n",
    "    \"\"\"Constructs a portfolio using the given hyperparameters\n",
    "    :param pred_stock: The stock to predict\n",
    "    :param n_components: The number of principal components the model should use\n",
    "    :param n_days: The number of days of data the model should consider\n",
    "    :param end_date: The last date of data the model should use\n",
    "    :param n_stocks: The number of stocks to be used by principal component analysis\n",
    "    :param is_sparse: Whether PCA should be sparse or not\n",
    "    \"\"\"\n",
    "    correlation_list = corr_list_for_single_stock(pred_stock, end_date, n_days)\n",
    "\n",
    "    # Get price history datasets\n",
    "    x, y = get_datasets(correlation_list, pred_stock, n_stocks, end_date, n_days)\n",
    "\n",
    "    # Standardize the features\n",
    "    X = StandardScaler().fit_transform(x)\n",
    "\n",
    "    # Do the PCA\n",
    "    if is_sparse:\n",
    "        pca = SparsePCA(n_components=n_components)\n",
    "    else:\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "    principal_components = pca.fit_transform(X)\n",
    "    principal_df = pd.DataFrame(data=principal_components, columns=[\"PC \" + str(g) for g in range(0, n_components)])\n",
    "\n",
    "    # Linear Regression of principal components\n",
    "    model = sm.OLS(principal_df, y).fit()\n",
    "\n",
    "    loadings = pd.DataFrame(pca.components_.T, index=x.columns)\n",
    "    loadings_dict = {stock: [] for stock in loadings[0].index.values}\n",
    "\n",
    "    for c_stock in loadings[0].index.values:\n",
    "        for pc in range(0, n_components):\n",
    "            loadings_dict[c_stock].append(loadings[pc][c_stock])\n",
    "\n",
    "    synthetic_position = {}\n",
    "    if n_components==1:\n",
    "        for c_stock in loadings_dict.keys():\n",
    "            synthetic_position[c_stock] = loadings_dict[c_stock][0]\n",
    "        return synthetic_position\n",
    "\n",
    "    for c_stock in loadings_dict.keys():\n",
    "        quantity = 0\n",
    "        for pc in range(0, n_components):\n",
    "            quantity += model.params[pc][pred_stock] * loadings_dict[c_stock][pc]\n",
    "        synthetic_position[c_stock] = quantity\n",
    "    return synthetic_position"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def hybrid_learning_replace(ticker) -> {}:\n",
    "    \"\"\"Determines which stocks to buy to emulate the performance of another\n",
    "    :param ticker: The stock for which a synthetic position should be calculated\n",
    "    :returns: Dictionary of replacement tickers and their quantities\n",
    "    \"\"\"\n",
    "    print(ticker)\n",
    "    return {}\n",
    "    #TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stock Market Backtester"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to run this simulator with different stocks and/or generate a new starting portfolio, do the following:\n",
    "1. Create a CSV file with the format: Ticker, Quantity\n",
    "2. Run **csvToComp.py** to generate text you can paste in as the *snp_composition* variable in **compToPickle.py**\n",
    "3. Run **compToPickle.py**\n",
    "4. Adjust the date range in **yfToPickle.py**\n",
    "5. Run **yfToPickle.py**, which will take a while, since it is downloading all of the price histories from Yahoo Finance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pyfolio as pf  #install using  pip3 install git+https://github.com/quantopian/pyfolio\n",
    "from enum import Enum\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "snp_comp_file_path = \"pickles/snp_composition.obj\"\n",
    "snp_price_file_path = \"pickles/snp_price.obj\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Composition data from pickle\n",
    "snp_comp_file = open(snp_comp_file_path, 'rb')\n",
    "snp_composition = pickle.load(snp_comp_file)\n",
    "snp_comp_file.close()\n",
    "\n",
    "# Price history downloaded from Yahoo Finance and stored in pickle\n",
    "snp_price_file = open(sptm_price_file_path, 'rb')\n",
    "price_history = pickle.load(snp_price_file)\n",
    "snp_price_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# Gets a list of all valid trading dates\n",
    "all_dates = price_history[list(all_tickers)[0]].axes[0].values\n",
    "dates = pd.DatetimeIndex(data=all_dates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def get_stock_price(ticker, day, time) -> float:\n",
    "    \"\"\"Retrieves the closing price of a stock on a given date\n",
    "    :param ticker: stock for which to retrieve the value\n",
    "    :param day: date on which to retrieve the value\n",
    "    :param time of day to calculate the value, either Time.OPEN or Time.CLOSE\n",
    "    \"\"\"\n",
    "    if time == Time.OPEN:\n",
    "        return round(price_history[ticker].Open[day], 2)\n",
    "    elif time == Time.CLOSE:\n",
    "        return round(price_history[ticker].Close[day], 2)\n",
    "\n",
    "\n",
    "class Time(Enum):\n",
    "    OPEN = 0\n",
    "    CLOSE = 1\n",
    "\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, ticker, cur_date, q=0):\n",
    "        \"\"\"Creates an object representing an owned stock\n",
    "        :param ticker: The stock's ticker symbol\n",
    "        :param q: How much of this stock is owned (this should only be used when constructing initial stock portfolios, as it essentially creates stock for free)\n",
    "        \"\"\"\n",
    "        self.ticker = ticker\n",
    "        self.quantity = q\n",
    "        self.avg_cost = get_stock_price(self.ticker, cur_date, Time.OPEN)\n",
    "\n",
    "    def buy(self, quantity, day_price):\n",
    "        \"\"\"Simulates a portfolio acquiring new stock\n",
    "        :param quantity: The amount of new stock to acquire\n",
    "        :param day_price: The price of the stock on the day of acquisition\n",
    "        \"\"\"\n",
    "        previously_owned = self.quantity\n",
    "        self.quantity += quantity\n",
    "        self.avg_cost += (previously_owned * self.avg_cost + quantity * day_price) / self.quantity\n",
    "\n",
    "    def sell(self, q, day_price):\n",
    "        \"\"\"Simulates a portfolio selling a stock\n",
    "        :param q: The amount of new stock to sell\n",
    "        :param day_price: The price of the stock on the day of acquisition\n",
    "        \"\"\"\n",
    "        previously_owned = self.quantity\n",
    "        self.quantity -= q\n",
    "        self.avg_cost -= (previously_owned * self.avg_cost - q * day_price) / self.quantity\n",
    "\n",
    "    def sell_all(self):\n",
    "        \"\"\"Simulates selling all of a stock\n",
    "        \"\"\"\n",
    "        self.quantity = 0\n",
    "        self.avg_cost = 0\n",
    "\n",
    "    def get_pct_change(self, change_date):\n",
    "        \"\"\"Gets the percent change of the stock based on the average cost\n",
    "        \"\"\"\n",
    "        change = self.get_change(change_date)\n",
    "        return 100 * (change / self.avg_cost)\n",
    "\n",
    "    def get_change(self, change_date) -> float:\n",
    "        \"\"\"Gets the difference between the stock's average purchase price and its current price\n",
    "        :returns: float\n",
    "        \"\"\"\n",
    "        current_price = get_stock_price(self.ticker, change_date, Time.OPEN)\n",
    "        return current_price - self.avg_cost\n",
    "\n",
    "\n",
    "class Portfolio:\n",
    "    def __init__(self, name, sim_start_date, starting_cash_balance: float = 1000000, starting_stocks=None,\n",
    "                 baseline=False, synthetic=False):\n",
    "        \"\"\"Creates a new portfolio\n",
    "        :param starting_cash_balance: The amount of cash the portfolio should start with (default 100,000.0)\n",
    "        :param starting_stocks: A dictionary containing the stocks the portfolio should begin with {'Ticker': Stock Object} (default is no starting stocks)\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        if starting_stocks is None:\n",
    "            starting_stocks = {}\n",
    "        self.stocks = starting_stocks\n",
    "        self.cash_balance = starting_cash_balance\n",
    "        self.value = 0\n",
    "        self.calculate_value(Time.OPEN, sim_start_date)\n",
    "        self.price_history = {}\n",
    "        self.closing_prices = []\n",
    "        self.returns = None\n",
    "        self.wash_sale_list = {}\n",
    "        self.baseline = baseline\n",
    "        self.synthetic = synthetic\n",
    "        self.diff = []\n",
    "\n",
    "    def calculate_value(self, time, calc_date):\n",
    "        \"\"\"Calculates the value of the portfolio based on the close of the global current date\n",
    "        :param calc_date: The date on whcih to calculate the value\n",
    "        :param time of day to calculate the value, either Time.OPEN or Time.CLOSE\n",
    "        \"\"\"\n",
    "        self.calculate_value_date(calc_date, time)\n",
    "\n",
    "    def calculate_value_date(self, c_day, time=Time.OPEN):\n",
    "        \"\"\"Calculates the value of the portfolio based on a specified date\n",
    "        :param c_day: the date on which the portfolio's value should be calculated\n",
    "        :param time of day to calculate the value, either Time.OPEN or (default) Time.CLOSE\n",
    "        \"\"\"\n",
    "\n",
    "        self.value = self.cash_balance\n",
    "        for stock in self.stocks.keys():\n",
    "            self.value += get_stock_price(stock, c_day, time) * self.stocks[stock].quantity\n",
    "\n",
    "        return self.value\n",
    "\n",
    "    def update_wash_sale_list(self):\n",
    "        \"\"\"Increments the counter for every item in the wash sale list and removes an item if the counter is >30\n",
    "        \"\"\"\n",
    "        remove_from_list = []\n",
    "        for wash_stock in self.wash_sale_list.keys():\n",
    "            self.wash_sale_list[wash_stock] += 1\n",
    "            if self.wash_sale_list[wash_stock] > 30:\n",
    "                remove_from_list.append(wash_stock)\n",
    "\n",
    "        for to_remove in remove_from_list:\n",
    "            self.wash_sale_list.pop(to_remove)\n",
    "\n",
    "    def begin_day(self, date_to_begin):\n",
    "        \"\"\"Calculates the starting value of the day and updates the wash sale list\n",
    "        \"\"\"\n",
    "        self.calculate_value(Time.OPEN, date_to_begin)\n",
    "        self.update_wash_sale_list()\n",
    "\n",
    "    def end_day(self, date_to_record):\n",
    "        \"\"\"\"Calculates the day's closing value and adds it to a list\n",
    "        :param date_to_record: The date associated with the ending day\n",
    "        \"\"\"\n",
    "        self.calculate_value(Time.OPEN, date_to_record)\n",
    "        self.price_history[date_to_record] = self.value\n",
    "        self.closing_prices.append(self.value)\n",
    "\n",
    "    def end_simulation(self, start_date_index, end_date_index):\n",
    "        \"\"\"Creates a Pandas Series of percent change of closing values and returns it\n",
    "        :param start_date_index: The index of the day that the simulation started\n",
    "        :param end_date_index: The index of the day that the simulation ended\n",
    "        \"\"\"\n",
    "        self.returns = pd.Series(data=self.closing_prices, index=dates[start_date_index:end_date_index]).pct_change()\n",
    "        return self.returns\n",
    "\n",
    "    def does_own_stock(self, ticker) -> bool:\n",
    "        \"\"\"Reports whether this portfolio contains a given stock\n",
    "        :param ticker: The stock to search for\n",
    "        \"\"\"\n",
    "        return ticker in self.stocks.keys()\n",
    "\n",
    "    def buy_stock(self, ticker, buy_date, quantity_to_buy):\n",
    "        \"\"\"Buys stock using cash balance if possible\n",
    "        :param buy_date: The date on which to buy the stocks\n",
    "        :param ticker: The stock to purchase\n",
    "        :param quantity_to_buy: The quantity of the stock to purchase (can be a float)\n",
    "        \"\"\"\n",
    "        stock_price = get_stock_price(ticker, buy_date, Time.OPEN)\n",
    "        trade_basis = stock_price * quantity_to_buy  #TODO can add fees here\n",
    "\n",
    "        # Exit if we cannot complete the trade\n",
    "        if trade_basis > self.cash_balance:\n",
    "            warnings.warn(\"Not enough cash to execute trade: buy \" + str(quantity_to_buy) + \" \" + ticker)\n",
    "            return\n",
    "\n",
    "        if ticker in self.wash_sale_list:\n",
    "            warnings.warn(\"Cannot buy \" + ticker + \": wash sale violation\")\n",
    "            return\n",
    "\n",
    "        # If we do not currently own the stock, create an entry\n",
    "        if ticker not in self.stocks.keys():\n",
    "            self.stocks[ticker] = Stock(ticker, buy_date)\n",
    "\n",
    "        # Execute the trade\n",
    "        self.stocks[ticker].buy(quantity_to_buy, stock_price)\n",
    "        self.cash_balance -= trade_basis\n",
    "\n",
    "    def sell_stock(self, ticker, sell_date, sell_quantity=0, sell_all=False):\n",
    "        \"\"\"Sells stock and adds to cash balance\n",
    "        :param sell_date: The date on which to sell the stocks\n",
    "        :param ticker: The stock to sell\n",
    "        :param sell_quantity: The quantity of the stock to sell (can be a float)\n",
    "        :param sell_all: Optional parameter to sell all stock\n",
    "        \"\"\"\n",
    "        stock_price = get_stock_price(ticker, sell_date, Time.OPEN)\n",
    "        # Ensure we have enough stock to sell\n",
    "        quantity_owned = self.stocks[ticker].sell_quantity\n",
    "        if sell_quantity > quantity_owned:\n",
    "            return\n",
    "\n",
    "        if sell_all or sell_quantity == quantity_owned:\n",
    "            self.stocks[ticker].sell_all()\n",
    "            self.cash_balance += quantity_owned * stock_price\n",
    "            self.stocks.pop(ticker)\n",
    "\n",
    "            # Update the wash sale list\n",
    "            self.wash_sale_list[ticker] = 0\n",
    "            return\n",
    "\n",
    "        # Do the trade\n",
    "        self.stocks[ticker].sell()\n",
    "        self.cash_balance += sell_quantity * stock_price  #TODO maybe things should be added to the wash sale list even if we just sell partial (but in theory we are always doing sellall)\n",
    "\n",
    "    def identify_losers(self, loser_date):\n",
    "        \"\"\"Identifies stocks that have dropped in value more than 5% since they were bought\n",
    "        :returns: List of all stocks that have dropped more than 5%\n",
    "        \"\"\"\n",
    "        identified_losers = []\n",
    "        for owned_stock in self.stocks.keys():\n",
    "            if self.stocks[owned_stock].get_change(loser_date) <= -1 * (0.05 * self.value):\n",
    "                identified_losers.append(owned_stock)\n",
    "        return identified_losers\n",
    "\n",
    "    def calculate_diff(self, baseline):\n",
    "        for m in range(0, len(self.closing_prices)):\n",
    "            self.diff.append(self.closing_prices[m] - baseline[m])\n",
    "\n",
    "def scale_portfolio_value(p, ratio, s_s_date):\n",
    "    \"\"\"Returns a new portfolio with quantities of each stock scaled by a specified ratio\"\"\"\n",
    "    new_p = {}\n",
    "    for s in p.stocks:\n",
    "        new_p[s] = Stock(s, s_s_date, p.stocks[s].quantity*ratio)\n",
    "\n",
    "    is_baseline = p.baseline\n",
    "    is_synthetic = p.synthetic\n",
    "    new_port = Portfolio(p.name, s_s_date, p.cash_balance, new_p, baseline=is_baseline, synthetic=is_synthetic)\n",
    "\n",
    "    return new_port\n",
    "\n",
    "\n",
    "def get_normalized_portfolios(p, s_s_date):\n",
    "    \"\"\"Accepts portfolios and returns new portfolios with the same value on the start date\n",
    "    Limitations: All portfolios but the synthetic one can only contain one stock\n",
    "    :param p: The portfolios to normalize (the baseline must be in position 1 and the synthetic portfolio must be marked)\n",
    "    :param s_s_date: The start date on which to normalize the portfolios\n",
    "    \"\"\"\n",
    "    return_ports = []\n",
    "\n",
    "    for port in p:\n",
    "        port_value = port.calculate_value_date(s_s_date)\n",
    "        ratio = 100 / port_value\n",
    "\n",
    "        new_port = scale_portfolio_value(port, ratio, s_s_date)\n",
    "\n",
    "        return_ports.append(new_port)\n",
    "\n",
    "    return return_ports\n",
    "\n",
    "\n",
    "def plot_portfolio(p, sim_end_date, sim_start_date):\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=round((sim_end_date - sim_start_date) / 10)))\n",
    "\n",
    "    for port in p:\n",
    "        days = []\n",
    "        y_price = []\n",
    "        for price in port.price_history:\n",
    "            days.append(price)\n",
    "            y_price.append(port.price_history[price])\n",
    "        plt.plot(days, y_price, label=port.name)\n",
    "\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "    plt.legend(loc='best')\n",
    "    # x1,x2,y1,y2 = plt.axis()\n",
    "    # plt.axis((x1,x2,0,200))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_differences(p, sim_end_date, sim_start_date):\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=round((sim_end_date - sim_start_date) / 10)))\n",
    "\n",
    "    for port in p:\n",
    "        days = []\n",
    "        for price in port.price_history:\n",
    "            days.append(price)\n",
    "        plt.plot(days, port.diff, label=port.name)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def get_correlations(portfolios):\n",
    "    correlations = {}\n",
    "    for p in portfolios:\n",
    "        if p.baseline:\n",
    "            for po in portfolios:\n",
    "                if not po.baseline:\n",
    "                    correlations[p.name+\"x\"+po.name] = po.returns.corr(p.returns)\n",
    "        return correlations\n",
    "\n",
    "\n",
    "def print_correlations(portfolios):\n",
    "    correlations = get_correlations(portfolios)\n",
    "    for correlation in correlations.keys():\n",
    "        print(correlation+\": \"+str(correlations[correlation]))\n",
    "\n",
    "\n",
    "def generate_end_report(portfolios, sim_start_date, sim_end_date):\n",
    "    plot_portfolio(portfolios, sim_end_date, sim_start_date)\n",
    "    for p in portfolios:\n",
    "        p.calculate_diff(portfolios[0].closing_prices)\n",
    "    plot_differences(portfolios, sim_end_date, sim_start_date)\n",
    "    # print_correlations(portfolios)\n",
    "\n",
    "def get_stats(portfolios):\n",
    "    correlations = get_correlations(portfolios)\n",
    "\n",
    "    mse = {}\n",
    "    for p in portfolios:\n",
    "        p.calculate_diff(portfolios[0].closing_prices)\n",
    "    for p in portfolios:\n",
    "        squared_diff = [val**2 for val in p.diff]\n",
    "        mse[p.name] = sum(squared_diff)/len(squared_diff)\n",
    "        if not p.baseline and not p.synthetic:\n",
    "            mse[\"CORR\"] = sum(squared_diff)/len(squared_diff)\n",
    "\n",
    "    mse_percent = {}\n",
    "    baseline = portfolios[0].returns[1:].values\n",
    "    for p in portfolios:\n",
    "        pct_changes = p.returns[1:].values\n",
    "        diff = [pct_changes[h]*100 - baseline[h]*100 for h in range(0, len(pct_changes))]\n",
    "        squared_diff = [val**2 for val in diff]\n",
    "        mse_percent[p.name] = sum(squared_diff)/len(squared_diff)\n",
    "\n",
    "    return {\"Correlation\": correlations, \"MSE\": mse, \"MSE_percent\":mse_percent}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def model_output_to_portfolio(model_output, output_date):\n",
    "    p = {}\n",
    "    for a_stock in model_output.keys():\n",
    "        p[a_stock] = Stock(a_stock, output_date, model_output[a_stock])\n",
    "    return p\n",
    "\n",
    "\n",
    "def run_simulation(sim_start_date, sim_end_date, portfolios, graph = True):\n",
    "    # Run the simulation\n",
    "    for date in range(sim_start_date, sim_end_date):\n",
    "        # Allow the portfolio to perform start of day updates\n",
    "        for sim_portfolio in portfolios:\n",
    "            sim_portfolio.begin_day(date)\n",
    "\n",
    "            # Determine which stocks should be tax loss harvested\n",
    "            # losers = sim_portfolio.identify_losers(date)\n",
    "\n",
    "            # for losing_stock in losers:\n",
    "            #     # Get dictionary of replacement stocks {'Ticker': Quantity}\n",
    "            #     replacement_stocks = hybrid_learning_replace(losing_stock)\n",
    "            #\n",
    "            #     # Sell the losing stock\n",
    "            #     portfolio.sell_stock(losing_stock, sell_all=True)\n",
    "            #\n",
    "            #     # Buy the replacement stocks\n",
    "            #     for buy_stock in replacement_stocks.keys():\n",
    "            #         portfolio.buy_stock(buy_stock, replacement_stocks[buy_stock])\n",
    "\n",
    "            # Allow the portfolio to perform end-of-day updates\n",
    "            sim_portfolio.end_day(all_dates[date])\n",
    "\n",
    "    returns = []\n",
    "\n",
    "    # Inform the portfolio that the simulation has ended\n",
    "    for portfolio in portfolios:\n",
    "        returns.append(portfolio.end_simulation(sim_start_date, sim_end_date))\n",
    "\n",
    "    if graph:\n",
    "        generate_end_report(portfolios, sim_start_date, sim_end_date)\n",
    "\n",
    "\n",
    "def simulate_stock(stock, sim_start_date, sim_end_date, tra_end_date, train_num_days, num_principal_components,\n",
    "                   num_pred_stocks, is_sparse, graph = True):\n",
    "    # Find correlated stock during training period\n",
    "    correlated_stock_ticker = list(corr_list_for_single_stock(stock, tra_end_date, train_num_days).keys())[1]\n",
    "\n",
    "    # Find synthetic stock portfolio during training period\n",
    "    synth_stocks = model_output_to_portfolio(\n",
    "        predict_portfolio(stock, num_principal_components, train_num_days, tra_end_date, num_pred_stocks, is_sparse),\n",
    "        sim_start_date)\n",
    "\n",
    "    synth_stock_portfolio = Portfolio(\"Synthetic\", sim_start_date, 0, starting_stocks=synth_stocks, synthetic=True)\n",
    "    correlated_stock_portfolio = Portfolio(correlated_stock_ticker, sim_start_date, 0, starting_stocks={\n",
    "        correlated_stock_ticker: Stock(correlated_stock_ticker, sim_start_date, 1)})\n",
    "    baseline_stock_portfolio = Portfolio(stock, sim_start_date, 0,\n",
    "                                         starting_stocks={stock: Stock(stock, sim_start_date, 1)}, baseline=True)\n",
    "\n",
    "    # ensure that the real stock is first in the portfolio\n",
    "    portfolios = get_normalized_portfolios(\n",
    "        [baseline_stock_portfolio, synth_stock_portfolio, correlated_stock_portfolio], sim_start_date)\n",
    "\n",
    "    run_simulation(sim_start_date, sim_end_date, portfolios, graph)\n",
    "    return get_stats(portfolios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [60]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_train_days\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     35\u001B[0m     num_train_days \u001B[38;5;241m=\u001B[39m tr_end_date\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 37\u001B[0m stats \u001B[38;5;241m=\u001B[39m \u001B[43msimulate_stock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstock_to_sim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_start_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_start_date\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mnum_validation_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtr_end_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_train_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_principal_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_pred_stocks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m mses\u001B[38;5;241m.\u001B[39mappend(stats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSynthetic\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     39\u001B[0m corr_mses\u001B[38;5;241m.\u001B[39mappend(stats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCORR\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "Input \u001B[0;32mIn [49]\u001B[0m, in \u001B[0;36msimulate_stock\u001B[0;34m(stock, sim_start_date, sim_end_date, tra_end_date, train_num_days, num_principal_components, num_pred_stocks, is_sparse, graph)\u001B[0m\n\u001B[1;32m     45\u001B[0m correlated_stock_ticker \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(corr_list_for_single_stock(stock, tra_end_date, train_num_days)\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# Find synthetic stock portfolio during training period\u001B[39;00m\n\u001B[1;32m     48\u001B[0m synth_stocks \u001B[38;5;241m=\u001B[39m model_output_to_portfolio(\n\u001B[0;32m---> 49\u001B[0m     \u001B[43mpredict_portfolio\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_principal_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_num_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtra_end_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_pred_stocks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_sparse\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     50\u001B[0m     sim_start_date)\n\u001B[1;32m     52\u001B[0m synth_stock_portfolio \u001B[38;5;241m=\u001B[39m Portfolio(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSynthetic\u001B[39m\u001B[38;5;124m\"\u001B[39m, sim_start_date, \u001B[38;5;241m0\u001B[39m, starting_stocks\u001B[38;5;241m=\u001B[39msynth_stocks, synthetic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     53\u001B[0m correlated_stock_portfolio \u001B[38;5;241m=\u001B[39m Portfolio(correlated_stock_ticker, sim_start_date, \u001B[38;5;241m0\u001B[39m, starting_stocks\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m     54\u001B[0m     correlated_stock_ticker: Stock(correlated_stock_ticker, sim_start_date, \u001B[38;5;241m1\u001B[39m)})\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mpredict_portfolio\u001B[0;34m(pred_stock, n_components, n_days, end_date, n_stocks, is_sparse)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_portfolio\u001B[39m(pred_stock, n_components, n_days, end_date, n_stocks, is_sparse):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"Constructs a portfolio using the given hyperparameters\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    :param pred_stock: The stock to predict\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    :param n_components: The number of principal components the model should use\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m    :param is_sparse: Whether PCA should be sparse or not\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m     correlation_list \u001B[38;5;241m=\u001B[39m \u001B[43mcorr_list_for_single_stock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_stock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_days\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;66;03m# Get price history datasets\u001B[39;00m\n\u001B[1;32m     13\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m get_datasets(correlation_list, pred_stock, n_stocks, end_date, n_days)\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mcorr_list_for_single_stock\u001B[0;34m(ticker, end_date, recent_days)\u001B[0m\n\u001B[1;32m     59\u001B[0m correlation_matrix \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(x_labels)):\n\u001B[0;32m---> 62\u001B[0m     correlation_matrix[x_labels[l]] \u001B[38;5;241m=\u001B[39m \u001B[43mticker_price_history\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43msptm_price_history\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43ml\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mClose\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpct_change\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mend_date\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrecent_days\u001B[49m\u001B[43m:\u001B[49m\u001B[43mend_date\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m correlation_matrix \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28msorted\u001B[39m(correlation_matrix\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39moperator\u001B[38;5;241m.\u001B[39mitemgetter(\u001B[38;5;241m1\u001B[39m), reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m correlation_matrix\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/series.py:2552\u001B[0m, in \u001B[0;36mSeries.corr\u001B[0;34m(self, other, method, min_periods)\u001B[0m\n\u001B[1;32m   2508\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcorr\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpearson\u001B[39m\u001B[38;5;124m\"\u001B[39m, min_periods\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m   2509\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2510\u001B[0m \u001B[38;5;124;03m    Compute correlation with `other` Series, excluding missing values.\u001B[39;00m\n\u001B[1;32m   2511\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2550\u001B[0m \u001B[38;5;124;03m    0.3\u001B[39;00m\n\u001B[1;32m   2551\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2552\u001B[0m     this, other \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malign\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjoin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minner\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   2553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(this) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   2554\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/series.py:4514\u001B[0m, in \u001B[0;36mSeries.align\u001B[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001B[0m\n\u001B[1;32m   4496\u001B[0m \u001B[38;5;129m@doc\u001B[39m(\n\u001B[1;32m   4497\u001B[0m     NDFrame\u001B[38;5;241m.\u001B[39malign,  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[1;32m   4498\u001B[0m     klass\u001B[38;5;241m=\u001B[39m_shared_doc_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mklass\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4512\u001B[0m     broadcast_axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   4513\u001B[0m ):\n\u001B[0;32m-> 4514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39malign(\n\u001B[1;32m   4515\u001B[0m         other,\n\u001B[1;32m   4516\u001B[0m         join\u001B[38;5;241m=\u001B[39mjoin,\n\u001B[1;32m   4517\u001B[0m         axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[1;32m   4518\u001B[0m         level\u001B[38;5;241m=\u001B[39mlevel,\n\u001B[1;32m   4519\u001B[0m         copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[1;32m   4520\u001B[0m         fill_value\u001B[38;5;241m=\u001B[39mfill_value,\n\u001B[1;32m   4521\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m   4522\u001B[0m         limit\u001B[38;5;241m=\u001B[39mlimit,\n\u001B[1;32m   4523\u001B[0m         fill_axis\u001B[38;5;241m=\u001B[39mfill_axis,\n\u001B[1;32m   4524\u001B[0m         broadcast_axis\u001B[38;5;241m=\u001B[39mbroadcast_axis,\n\u001B[1;32m   4525\u001B[0m     )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# def simulate_stock(stock: {__eq__},\n",
    "#                    sim_start_date: Any,\n",
    "#                    sim_end_date: {__sub__},\n",
    "#                    tr_end_date: {__sub__},\n",
    "#                    train_num_days: Any,\n",
    "#                    num_principal_components: Any,\n",
    "#                    num_pred_stocks: Any,\n",
    "#                    sparse: Any) -> None\n",
    "#                    graph: bool = True) -> None\n",
    "#simulate_stock('AAPL', test_start_date, test_start_date + 20, train_end_date, 120, 2, 10, False, graph = True)\n",
    "\n",
    "i=0\n",
    "hyperparameters = {}\n",
    "low_mse = 10000000\n",
    "corr_mse = 0\n",
    "for n_principal_components in range(1, 10):\n",
    "    for num_train_days in [0, 30, 60, 90, 150, 180, 360]:\n",
    "        for n_pred_stocks in [2, 3, 5, 10, 15, 25, 50, 100]:\n",
    "            if n_principal_components>=n_pred_stocks:\n",
    "                continue\n",
    "            for sparse in [True, False]:\n",
    "                mses = []\n",
    "                corr_mses = []\n",
    "                for r in range(0, 100): # repeats a simulation 100 times to get an average measure of the MSE for these hyperparameters over different stocks and time periods\n",
    "                    # tr_end_date should within [train_start_date+num_train_days, train_end_date-num_validation_days] to ensure it does not leak into the test set, even after it is validated\n",
    "                    tr_end_date = random.randint(train_start_date+num_train_days, train_end_date - num_validation_days)\n",
    "\n",
    "                    # validation starts on the soonest day after training is done\n",
    "                    validation_start_date = tr_end_date+1\n",
    "\n",
    "                    num = random.randint(0, len(all_tickers)-1)\n",
    "                    stock_to_sim = list(all_tickers)[num]\n",
    "\n",
    "                    if num_train_days==0:\n",
    "                        num_train_days = tr_end_date-1\n",
    "\n",
    "                    stats = simulate_stock(stock_to_sim, validation_start_date, validation_start_date+num_validation_days, tr_end_date, num_train_days, n_principal_components, n_pred_stocks, sparse, graph=False)\n",
    "                    mses.append(stats['MSE']['Synthetic'])\n",
    "                    corr_mses.append(stats['MSE'][\"CORR\"])\n",
    "\n",
    "                print(i)\n",
    "                i+=1\n",
    "\n",
    "                avg_mse = sum(mses)/100\n",
    "                avg_corr_mse = sum(corr_mses)/100\n",
    "\n",
    "                if avg_mse<=low_mse:\n",
    "                    low_mse = avg_mse\n",
    "                    corr_mse = avg_corr_mse\n",
    "                    hyperparameters = {'npca': n_principal_components, 'ntd': num_train_days, 'nps': n_pred_stocks, 'sparse': sparse}\n",
    "print(low_mse)\n",
    "print(corr_mse)\n",
    "print(hyperparameters)\n",
    "\n",
    "#0.0001232489645044427\n",
    "#{'npca': 2, 'ntd': 30, 'nps': 3, 'sparse': True}\n",
    "# simulate_stock('COST', test_start_date, test_start_date + 20, train_end_date, 30, 2, 3, True, graph = True)\n",
    "\n",
    "# 0.010779939104229553\n",
    "# {'npca': 4, 'ntd': 30, 'nps': 5, 'sparse': False}\n",
    "# simulate_stock(\"COST\", test_start_date, test_start_date+30, train_end_date, 30, 4, 5, True, graph=True)\n",
    "\n",
    "# 46.56410051362909\n",
    "# {'npca': 4, 'ntd': 30, 'nps': 25, 'sparse': False}\n",
    "\n",
    "# 47.28842525584654\n",
    "# {'npca': 7, 'ntd': 90, 'nps': 25, 'sparse': True}\n",
    "\n",
    "# 36.120000133501776\n",
    "# {'npca': 1, 'ntd': 150, 'nps': 15, 'sparse': False}\n",
    "\n",
    "\n",
    "# 22.05078125720328\n",
    "# {'npca': 3, 'ntd': 360, 'nps': 5, 'sparse': False}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "##pf.create_returns_tear_sheet(returns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}