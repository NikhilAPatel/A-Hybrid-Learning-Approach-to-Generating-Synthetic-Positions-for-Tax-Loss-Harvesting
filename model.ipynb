{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A Hybrid Learning Approach to Synthetic Position Construction for Tax Loss Harvesting"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generation of Synthetic Positions Using Hybrid Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "import statsmodels.api as sm\n",
    "import operator\n",
    "from deprecated import deprecated\n",
    "\n",
    "corr_matrix_file_path = \"pickles/corr_matrix.obj\"\n",
    "x_labels_file_path = \"pickles/X_labels.obj\"\n",
    "sptm_comp_file_path = \"pickles/sptm_composition.obj\"\n",
    "sptm_price_file_path = \"pickles/sptm_price.obj\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Composition data from pickle\n",
    "sptm_comp_file = open(sptm_comp_file_path, 'rb')\n",
    "sptm_composition = pickle.load(sptm_comp_file)\n",
    "sptm_comp_file.close()\n",
    "\n",
    "# Price history downloaded from Yahoo Finance and stored in pickle\n",
    "sptm_price_file = open(sptm_price_file_path, 'rb')\n",
    "sptm_price_history = pickle.load(sptm_price_file)\n",
    "sptm_price_file.close()\n",
    "\n",
    "all_tickers = sptm_composition.keys()\n",
    "\n",
    "# Gets a list of all valid trading dates\n",
    "all_dates = sptm_price_history[list(all_tickers)[0]].axes[0].values\n",
    "dates = pd.DatetimeIndex(data=all_dates)\n",
    "current_date = all_dates[0]\n",
    "\n",
    "# 80/20 Test/Train Split\n",
    "# Data Range: 2015-01-02 - 2020-08-10\n",
    "# Testing Range: 2020-08-11 - 2021-12-31\n",
    "train_start_date = 0\n",
    "train_end_date = 1410\n",
    "test_start_date = 1411\n",
    "test_end_date = 1762"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding Highly Correlated Stocks\n",
    "#### Use the *do_corr_matrix_regen* variable to tell the code to generate the correlation matrix, else it will load it from a pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "num_stocks = len(all_tickers)\n",
    "\n",
    "\n",
    "@deprecated(reason=\"Switched to generating singular correlation lists on the fly\")\n",
    "def regenerate_corr_matrix(end_date, recent_days):\n",
    "    \"\"\"Calculates the correlation between every stock's percent time series\n",
    "    :param end_date: The last date for which data should be used to generate the correlation matrix\n",
    "    :param recent_days: How many days of price history should be used to calculate the correlation matrix\n",
    "    \"\"\"\n",
    "    x_vars = []\n",
    "    x_labels = []\n",
    "\n",
    "    for ticker in all_tickers:\n",
    "        x_vars.append(sptm_price_history[ticker].Close.pct_change().iloc[end_date - recent_days:end_date])\n",
    "        x_labels.append(ticker)\n",
    "\n",
    "    correlation_matrix = [[0 for _ in range(0, num_stocks)] for _ in range(0, num_stocks)]\n",
    "\n",
    "    for l in range(0, num_stocks):\n",
    "        for m in range(0, num_stocks):\n",
    "            correlation_matrix[l][m] = x_vars[l].corr(x_vars[m])\n",
    "    correlation_matrix = pd.DataFrame(correlation_matrix, columns=x_labels[0:num_stocks])\n",
    "\n",
    "    correlation_matrix_file = open(corr_matrix_file_path, 'wb')\n",
    "    pickle.dump(correlation_matrix, correlation_matrix_file)\n",
    "    correlation_matrix_file.close()\n",
    "\n",
    "    x_labels_file = open(x_labels_file_path, 'wb')\n",
    "    pickle.dump(x_labels, x_labels_file)\n",
    "    x_labels_file.close()\n",
    "\n",
    "\n",
    "@deprecated(reason=\"Switched to generating singular correlation lists on the fly\")\n",
    "def load_corr_matrix():\n",
    "    \"\"\"Loads correlation matrix and labels from pickles\n",
    "    :returns: [correlation_matrix, x_labels]\n",
    "    \"\"\"\n",
    "    # Covariance Matrix from pickle\n",
    "    corr_matrix_file = open(corr_matrix_file_path, 'rb')\n",
    "    correlation_matrix = pickle.load(corr_matrix_file)\n",
    "    corr_matrix_file.close()\n",
    "\n",
    "    # X_Labels from pickle\n",
    "    x_labels_file = open(x_labels_file_path, 'rb')\n",
    "    x_labels = pickle.load(x_labels_file)\n",
    "    x_labels_file.close()\n",
    "\n",
    "    return correlation_matrix, x_labels\n",
    "\n",
    "\n",
    "def corr_list_for_single_stock(ticker, end_date, recent_days):\n",
    "    x_labels = []\n",
    "\n",
    "    ticker_price_history = sptm_price_history[ticker].Close.pct_change().iloc[end_date - recent_days:end_date]\n",
    "\n",
    "    for tickers in sptm_price_history.keys():\n",
    "        x_labels.append(tickers)\n",
    "\n",
    "    correlation_matrix = {}\n",
    "\n",
    "    for l in range(0, len(x_labels)):\n",
    "        correlation_matrix[x_labels[l]] = ticker_price_history.corr(\n",
    "            sptm_price_history[x_labels[l]].Close.pct_change().iloc[end_date - recent_days:end_date])\n",
    "    correlation_matrix = dict(sorted(correlation_matrix.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "    return correlation_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def filter_substantially_similar_securities(ticker, series, additional_stocks=None):\n",
    "    \"\"\"Filters out the stocks you cannot buy because of a wash sale\n",
    "    :param series: The series of correlated stocks that should be filtered\n",
    "    :param ticker: Ticker to filter out securities for\n",
    "    :param additional_stocks: Any additional stocks you want to filter out (default = None)\n",
    "    \"\"\"\n",
    "    if additional_stocks is None:\n",
    "        additional_stocks = []\n",
    "\n",
    "    # Handles Google having both GOOG and GOOGL in the dataset\n",
    "    if ticker == \"GOOG\" or ticker:\n",
    "        additional_stocks.append(\"GOOG\")\n",
    "        additional_stocks.append(\"GOOGL\")\n",
    "\n",
    "    additional_stocks.append(ticker)\n",
    "\n",
    "    for remove_stock in additional_stocks:\n",
    "        series.pop(series.index(remove_stock))\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def find_top_correlated_stocks(correlation_list, ticker, n):\n",
    "    \"\"\"Finds the top n stocks correlated with a given stock\n",
    "    :param correlation_list: The correlation list to get the top correlated stocks from\n",
    "    :param n: the number of correlated stocks to return\n",
    "    :param ticker: The ticker for which correlated stocks should be found\n",
    "    :returns: A list (sorted by most correlation) of correlated stocks\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_correlations = filter_substantially_similar_securities(ticker, list(correlation_list.keys()))\n",
    "\n",
    "    return filtered_correlations[:n]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Principle Component Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def get_price_histories_dataframe(stocks, target_stock, end_date, recent_days):\n",
    "    \"\"\"Compiles a DataFrame with the price histories of the specified stocks\n",
    "    :param target_stock: The stock for which the dataset should be created\n",
    "    :param stocks: The stocks to include in the DataFrame\n",
    "    :param end_date: The last date for which data should be used to get the price history\n",
    "    :param recent_days: How many days of price history should be fetched\n",
    "    :returns: (Features DataFrame, Target DataFrame)\"\"\"\n",
    "    d = {}\n",
    "    for correlated_stock in stocks:\n",
    "        d[correlated_stock] = sptm_price_history[correlated_stock].Close.values[end_date - recent_days:end_date]\n",
    "    target = pd.DataFrame(\n",
    "        {target_stock: sptm_price_history[target_stock].Close.values[end_date - recent_days:end_date]})\n",
    "    return pd.DataFrame(data=d), target\n",
    "\n",
    "\n",
    "def get_datasets(correlation_list, target_stock, n, end_date, recent_days):\n",
    "    \"\"\"Compiles the necessary datasets for PCA. One with the price history of the features, and one with the price history of the target\n",
    "    :param correlation_list: The correlation list to get the top correlated stocks from\n",
    "    :param target_stock: The stock for which the dataset should be created\n",
    "    :param n: the number of datasets to get\n",
    "    :param end_date: The last date for which data should be used to get the price history\n",
    "    :param recent_days: How many days of price history should be fetched\n",
    "    :returns: (x, y) where x and y are DataFrames\n",
    "    \"\"\"\n",
    "    corr_stocks = find_top_correlated_stocks(correlation_list, target_stock, n)\n",
    "    return get_price_histories_dataframe(corr_stocks, target_stock, end_date, recent_days)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def predict_portfolio(pred_stock, n_components, n_days, end_date, n_stocks, sparse):\n",
    "    \"\"\"Constructs a portfolio using the given hyperparameters\n",
    "    :param pred_stock: The stock to predict\n",
    "    :param n_components: The number of principal components the model should use\n",
    "    :param n_days: The number of days of data the model should consider\n",
    "    :param end_date: The last date of data the model should use\n",
    "    :param n_stocks: The number of stocks to be used by principal component analysis\n",
    "    :param sparse: Whether PCA should be sparse or not\n",
    "    \"\"\"\n",
    "    correlation_list = corr_list_for_single_stock('AAPL', end_date, n_days)\n",
    "\n",
    "    # Get price history datasets\n",
    "    x, y = get_datasets(correlation_list, pred_stock, n_stocks, end_date, n_days)\n",
    "\n",
    "    # Standardize the features\n",
    "    X = StandardScaler().fit_transform(x)\n",
    "\n",
    "    # Do the PCA\n",
    "    if sparse:\n",
    "        pca = SparsePCA(n_components=n_components)\n",
    "    else:\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "    principal_components = pca.fit_transform(X)\n",
    "    principal_df = pd.DataFrame(data=principal_components, columns=[\"PC \" + str(i) for i in range(0, n_components)])\n",
    "\n",
    "    # Linear Regression of principal components\n",
    "    model = sm.OLS(principal_df, y).fit()\n",
    "\n",
    "    loadings = pd.DataFrame(pca.components_.T, index=x.columns)\n",
    "    loadings_dict = {stock: [] for stock in loadings[0].index.values}\n",
    "\n",
    "    for c_stock in loadings[0].index.values:\n",
    "        for pc in range(0, n_components):\n",
    "            loadings_dict[c_stock].append(loadings[pc][c_stock])\n",
    "\n",
    "    synthetic_position = {}\n",
    "    if n_components==1:\n",
    "        for c_stock in loadings_dict.keys():\n",
    "            synthetic_position[c_stock] = loadings_dict[c_stock][0]\n",
    "        return synthetic_position\n",
    "\n",
    "    for c_stock in loadings_dict.keys():\n",
    "        quantity = 0\n",
    "        for pc in range(0, n_components):\n",
    "            quantity += model.params[pc][pred_stock] * loadings_dict[c_stock][pc]\n",
    "        synthetic_position[c_stock] = quantity\n",
    "\n",
    "    return synthetic_position"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def hybrid_learning_replace(ticker) -> {}:\n",
    "    \"\"\"Determines which stocks to buy to emulate the performance of another\n",
    "    :param ticker: The stock for which a synthetic position should be calculated\n",
    "    :returns: Dictionary of replacement tickers and their quantities\n",
    "    \"\"\"\n",
    "    print(ticker)\n",
    "    return {}\n",
    "    #TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stock Market Backtester"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to run this simulator with different stocks and/or generate a new starting portfolio, do the following:\n",
    "1. Create a CSV file with the format: Ticker, Quantity\n",
    "2. Run **csvToComp.py** to generate text you can paste in as the *snp_composition* variable in **compToPickle.py**\n",
    "3. Run **compToPickle.py**\n",
    "4. Adjust the date range in **yfToPickle.py**\n",
    "5. Run **yfToPickle.py**, which will take a while, since it is downloading all of the price histories from Yahoo Finance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pyfolio as pf  #install using  pip3 install git+https://github.com/quantopian/pyfolio\n",
    "from enum import Enum\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "% matplotlib inline\n",
    "\n",
    "snp_comp_file_path = \"pickles/snp_composition.obj\"\n",
    "snp_price_file_path = \"pickles/snp_price.obj\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# Composition data from pickle\n",
    "snp_comp_file = open(snp_comp_file_path, 'rb')\n",
    "snp_composition = pickle.load(snp_comp_file)\n",
    "snp_comp_file.close()\n",
    "\n",
    "# Price history downloaded from Yahoo Finance and stored in pickle\n",
    "snp_price_file = open(sptm_price_file_path, 'rb')\n",
    "price_history = pickle.load(snp_price_file)\n",
    "snp_price_file.close()\n",
    "\n",
    "all_tickers = snp_composition.keys()\n",
    "\n",
    "# Gets a list of all valid trading dates\n",
    "all_dates = price_history[list(all_tickers)[0]].axes[0].values\n",
    "dates = pd.DatetimeIndex(data=all_dates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def get_stock_price(ticker, day, time) -> float:\n",
    "    \"\"\"Retrieves the closing price of a stock on a given date\n",
    "    :param ticker: stock for which to retrieve the value\n",
    "    :param day: date on which to retrieve the value\n",
    "    :param time of day to calculate the value, either Time.OPEN or Time.CLOSE\n",
    "    \"\"\"\n",
    "    if time == Time.OPEN:\n",
    "        return round(price_history[ticker].Open[day], 2)\n",
    "    elif time == Time.CLOSE:\n",
    "        return round(price_history[ticker].Close[day], 2)\n",
    "\n",
    "\n",
    "class Time(Enum):\n",
    "    OPEN = 0\n",
    "    CLOSE = 1\n",
    "\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, ticker, cur_date, q=0):\n",
    "        \"\"\"Creates an object representing an owned stock\n",
    "        :param ticker: The stock's ticker symbol\n",
    "        :param q: How much of this stock is owned (this should only be used when constructing initial stock portfolios, as it essentially creates stock for free)\n",
    "        \"\"\"\n",
    "        self.ticker = ticker\n",
    "        self.quantity = q\n",
    "        self.avg_cost = get_stock_price(self.ticker, cur_date, Time.CLOSE)\n",
    "\n",
    "    def buy(self, quantity, day_price):\n",
    "        \"\"\"Simulates a portfolio acquiring new stock\n",
    "        :param quantity: The amount of new stock to acquire\n",
    "        :param day_price: The price of the stock on the day of acquisition\n",
    "        \"\"\"\n",
    "        previously_owned = self.quantity\n",
    "        self.quantity += quantity\n",
    "        self.avg_cost += (previously_owned * self.avg_cost + quantity * day_price) / self.quantity\n",
    "\n",
    "    def sell(self, q, day_price):\n",
    "        \"\"\"Simulates a portfolio selling a stock\n",
    "        :param q: The amount of new stock to sell\n",
    "        :param day_price: The price of the stock on the day of acquisition\n",
    "        \"\"\"\n",
    "        previously_owned = self.quantity\n",
    "        self.quantity -= q\n",
    "        self.avg_cost -= (previously_owned * self.avg_cost - q * day_price) / self.quantity\n",
    "\n",
    "    def sell_all(self):\n",
    "        \"\"\"Simulates selling all of a stock\n",
    "        \"\"\"\n",
    "        self.quantity = 0\n",
    "        self.avg_cost = 0\n",
    "\n",
    "    def get_pct_change(self, change_date):\n",
    "        \"\"\"Gets the percent change of the stock based on the average cost\n",
    "        \"\"\"\n",
    "        change = self.get_change(change_date)\n",
    "        return 100 * (change / self.avg_cost)\n",
    "\n",
    "    def get_change(self, change_date) -> float:\n",
    "        \"\"\"Gets the difference between the stock's average purchase price and its current price\n",
    "        :returns: float\n",
    "        \"\"\"\n",
    "        current_price = get_stock_price(self.ticker, change_date, Time.CLOSE)\n",
    "        return current_price - self.avg_cost\n",
    "\n",
    "\n",
    "class Portfolio:\n",
    "    def __init__(self, name, sim_start_date, starting_cash_balance: float = 1000000, starting_stocks=None,\n",
    "                 baseline=False, synthetic=False):\n",
    "        \"\"\"Creates a new portfolio\n",
    "        :param starting_cash_balance: The amount of cash the portfolio should start with (default 100,000.0)\n",
    "        :param starting_stocks: A dictionary containing the stocks the portfolio should begin with {'Ticker': Stock Object} (default is no starting stocks)\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        if starting_stocks is None:\n",
    "            starting_stocks = {}\n",
    "        self.stocks = starting_stocks\n",
    "        self.cash_balance = starting_cash_balance\n",
    "        self.value = 0\n",
    "        self.calculate_value(Time.CLOSE, sim_start_date)\n",
    "        self.price_history = {}\n",
    "        self.closing_prices = []\n",
    "        self.returns = None\n",
    "        self.wash_sale_list = {}\n",
    "        self.baseline = baseline\n",
    "        self.synthetic = synthetic\n",
    "        self.diff = []\n",
    "\n",
    "    def calculate_value(self, time, calc_date):\n",
    "        \"\"\"Calculates the value of the portfolio based on the close of the global current date\n",
    "        :param calc_date: The date on whcih to calculate the value\n",
    "        :param time of day to calculate the value, either Time.OPEN or Time.CLOSE\n",
    "        \"\"\"\n",
    "        self.calculate_value_date(calc_date, time)\n",
    "\n",
    "    def calculate_value_date(self, c_day, time=Time.CLOSE):\n",
    "        \"\"\"Calculates the value of the portfolio based on a specified date\n",
    "        :param c_day: the date on which the portfolio's value should be calculated\n",
    "        :param time of day to calculate the value, either Time.OPEN or (default) Time.CLOSE\n",
    "        \"\"\"\n",
    "\n",
    "        self.value = self.cash_balance\n",
    "        for stock in self.stocks.keys():\n",
    "            self.value += get_stock_price(stock, c_day, time) * self.stocks[stock].quantity\n",
    "\n",
    "        return self.value\n",
    "\n",
    "    def update_wash_sale_list(self):\n",
    "        \"\"\"Increments the counter for every item in the wash sale list and removes an item if the counter is >30\n",
    "        \"\"\"\n",
    "        remove_from_list = []\n",
    "        for wash_stock in self.wash_sale_list.keys():\n",
    "            self.wash_sale_list[wash_stock] += 1\n",
    "            if self.wash_sale_list[wash_stock] > 30:\n",
    "                remove_from_list.append(wash_stock)\n",
    "\n",
    "        for to_remove in remove_from_list:\n",
    "            self.wash_sale_list.pop(to_remove)\n",
    "\n",
    "    def begin_day(self, date_to_begin):\n",
    "        \"\"\"Calculates the starting value of the day and updates the wash sale list\n",
    "        \"\"\"\n",
    "        self.calculate_value(Time.CLOSE, date_to_begin)\n",
    "        self.update_wash_sale_list()\n",
    "\n",
    "    def end_day(self, date_to_record):\n",
    "        \"\"\"\"Calculates the day's closing value and adds it to a list\n",
    "        :param date_to_record: The date associated with the ending day\n",
    "        \"\"\"\n",
    "        self.calculate_value(Time.CLOSE, date_to_record)\n",
    "        self.price_history[date_to_record] = self.value\n",
    "        self.closing_prices.append(self.value)\n",
    "\n",
    "    def end_simulation(self, start_date_index, end_date_index):\n",
    "        \"\"\"Creates a Pandas Series of percent change of closing values and returns it\n",
    "        :param start_date_index: The index of the day that the simulation started\n",
    "        :param end_date_index: The index of the day that the simulation ended\n",
    "        \"\"\"\n",
    "        self.returns = pd.Series(data=self.closing_prices, index=dates[start_date_index:end_date_index]).pct_change()\n",
    "        return self.returns\n",
    "\n",
    "    def does_own_stock(self, ticker) -> bool:\n",
    "        \"\"\"Reports whether this portfolio contains a given stock\n",
    "        :param ticker: The stock to search for\n",
    "        \"\"\"\n",
    "        return ticker in self.stocks.keys()\n",
    "\n",
    "    def buy_stock(self, ticker, buy_date, quantity_to_buy):\n",
    "        \"\"\"Buys stock using cash balance if possible\n",
    "        :param buy_date: The date on which to buy the stocks\n",
    "        :param ticker: The stock to purchase\n",
    "        :param quantity_to_buy: The quantity of the stock to purchase (can be a float)\n",
    "        \"\"\"\n",
    "        stock_price = get_stock_price(ticker, buy_date, Time.CLOSE)\n",
    "        trade_basis = stock_price * quantity_to_buy  #TODO can add fees here\n",
    "\n",
    "        # Exit if we cannot complete the trade\n",
    "        if trade_basis > self.cash_balance:\n",
    "            warnings.warn(\"Not enough cash to execute trade: buy \" + str(quantity_to_buy) + \" \" + ticker)\n",
    "            return\n",
    "\n",
    "        if ticker in self.wash_sale_list:\n",
    "            warnings.warn(\"Cannot buy \" + ticker + \": wash sale violation\")\n",
    "            return\n",
    "\n",
    "        # If we do not currently own the stock, create an entry\n",
    "        if ticker not in self.stocks.keys():\n",
    "            self.stocks[ticker] = Stock(ticker, buy_date)\n",
    "\n",
    "        # Execute the trade\n",
    "        self.stocks[ticker].buy(quantity_to_buy, stock_price)\n",
    "        self.cash_balance -= trade_basis\n",
    "\n",
    "    def sell_stock(self, ticker, sell_date, sell_quantity=0, sell_all=False):\n",
    "        \"\"\"Sells stock and adds to cash balance\n",
    "        :param sell_date: The date on which to sell the stocks\n",
    "        :param ticker: The stock to sell\n",
    "        :param sell_quantity: The quantity of the stock to sell (can be a float)\n",
    "        :param sell_all: Optional parameter to sell all stock\n",
    "        \"\"\"\n",
    "        stock_price = get_stock_price(ticker, sell_date, Time.CLOSE)\n",
    "        # Ensure we have enough stock to sell\n",
    "        quantity_owned = self.stocks[ticker].sell_quantity\n",
    "        if sell_quantity > quantity_owned:\n",
    "            return\n",
    "\n",
    "        if sell_all or sell_quantity == quantity_owned:\n",
    "            self.stocks[ticker].sell_all()\n",
    "            self.cash_balance += quantity_owned * stock_price\n",
    "            self.stocks.pop(ticker)\n",
    "\n",
    "            # Update the wash sale list\n",
    "            self.wash_sale_list[ticker] = 0\n",
    "            return\n",
    "\n",
    "        # Do the trade\n",
    "        self.stocks[ticker].sell()\n",
    "        self.cash_balance += sell_quantity * stock_price  #TODO maybe things should be added to the wash sale list even if we just sell partial (but in theory we are always doing sellall)\n",
    "\n",
    "    def identify_losers(self, loser_date):\n",
    "        \"\"\"Identifies stocks that have dropped in value more than 5% since they were bought\n",
    "        :returns: List of all stocks that have dropped more than 5%\n",
    "        \"\"\"\n",
    "        identified_losers = []\n",
    "        for owned_stock in self.stocks.keys():\n",
    "            if self.stocks[owned_stock].get_change(loser_date) <= -1 * (0.05 * self.value):\n",
    "                identified_losers.append(owned_stock)\n",
    "        return identified_losers\n",
    "\n",
    "    def calculate_diff(self, baseline):\n",
    "        for m in range(0, len(self.closing_prices)):\n",
    "            self.diff.append(self.closing_prices[m] - baseline[m])\n",
    "\n",
    "\n",
    "def get_normalized_portfolios(p, s_s_date):\n",
    "    \"\"\"Accepts portfolios and returns new portfolios with the same value on the start date\n",
    "    Limitations: All portfolios but the synthetic one can only contain one stock\n",
    "    :param p: The portfolios to normalize (the baseline must be in position 1 and the synthetic portfolio must be marked)\n",
    "    :param s_s_date: The start date on which to normalize the portfolios\n",
    "    \"\"\"\n",
    "    synth = None\n",
    "    for port in p:\n",
    "        if port.synthetic:\n",
    "            synth = port\n",
    "\n",
    "    return_ports = []\n",
    "\n",
    "    for port in p:\n",
    "        if port == synth:\n",
    "            continue\n",
    "\n",
    "        synth_value = synth.calculate_value_date(s_s_date)\n",
    "        port_value = port.calculate_value_date(s_s_date)\n",
    "        ratio = synth_value / port_value\n",
    "\n",
    "        new_stock_ticker = list(port.stocks.keys())[0]\n",
    "\n",
    "        is_baseline = port.baseline\n",
    "\n",
    "        new_port = Portfolio(port.name, s_s_date, port.cash_balance,\n",
    "                             {new_stock_ticker: Stock(new_stock_ticker, s_s_date, ratio)}, baseline=is_baseline)\n",
    "\n",
    "        return_ports.append(new_port)\n",
    "\n",
    "    return_ports.append(synth)\n",
    "    return return_ports\n",
    "\n",
    "\n",
    "def plot_portfolio(p, sim_end_date, sim_start_date):\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=round((sim_end_date - sim_start_date) / 10)))\n",
    "\n",
    "    for port in p:\n",
    "        days = []\n",
    "        y_price = []\n",
    "        for price in port.price_history:\n",
    "            days.append(price)\n",
    "            y_price.append(port.price_history[price])\n",
    "        plt.plot(days, y_price, label=port.name)\n",
    "\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_differences(p, sim_end_date, sim_start_date):\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=round((sim_end_date - sim_start_date) / 10)))\n",
    "\n",
    "    for port in p:\n",
    "        days = []\n",
    "        for price in port.price_history:\n",
    "            days.append(price)\n",
    "        plt.plot(days, port.diff, label=port.name)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def get_correlations(portfolios):\n",
    "    correlations = {}\n",
    "    for p in portfolios:\n",
    "        if p.baseline:\n",
    "            for po in portfolios:\n",
    "                if not po.baseline:\n",
    "                    correlations[p.name+\"x\"+po.name] = po.returns.corr(p.returns)\n",
    "        return correlations\n",
    "\n",
    "\n",
    "def print_correlations(portfolios):\n",
    "    correlations = get_correlations(portfolios)\n",
    "    for correlation in correlations.keys():\n",
    "        print(correlation+\": \"+str(correlations[correlation]))\n",
    "\n",
    "\n",
    "def generate_end_report(portfolios, sim_start_date, sim_end_date):\n",
    "    plot_portfolio(portfolios, sim_end_date, sim_start_date)\n",
    "    for p in portfolios:\n",
    "        p.calculate_diff(portfolios[0].closing_prices)\n",
    "    plot_differences(portfolios, sim_end_date, sim_start_date)\n",
    "    print_correlations(portfolios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def model_output_to_portfolio(model_output, output_date):\n",
    "    p = {}\n",
    "    for a_stock in model_output.keys():\n",
    "        p[a_stock] = Stock(a_stock, output_date, model_output[a_stock])\n",
    "    return p\n",
    "\n",
    "\n",
    "def run_simulation(sim_start_date, sim_end_date, portfolios, graph = True):\n",
    "    # Run the simulation\n",
    "    for date in range(sim_start_date, sim_end_date):\n",
    "        # Allow the portfolio to perform start of day updates\n",
    "        for sim_portfolio in portfolios:\n",
    "            sim_portfolio.begin_day(date)\n",
    "\n",
    "            # Determine which stocks should be tax loss harvested\n",
    "            losers = sim_portfolio.identify_losers(date)\n",
    "\n",
    "            # for losing_stock in losers:\n",
    "            #     # Get dictionary of replacement stocks {'Ticker': Quantity}\n",
    "            #     replacement_stocks = hybrid_learning_replace(losing_stock)\n",
    "            #\n",
    "            #     # Sell the losing stock\n",
    "            #     portfolio.sell_stock(losing_stock, sell_all=True)\n",
    "            #\n",
    "            #     # Buy the replacement stocks\n",
    "            #     for buy_stock in replacement_stocks.keys():\n",
    "            #         portfolio.buy_stock(buy_stock, replacement_stocks[buy_stock])\n",
    "\n",
    "            # Allow the portfolio to perform end-of-day updates\n",
    "            sim_portfolio.end_day(all_dates[date])\n",
    "\n",
    "    returns = []\n",
    "\n",
    "    # Inform the portfolio that the simulation has ended\n",
    "    for portfolio in portfolios:\n",
    "        returns.append(portfolio.end_simulation(sim_start_date, sim_end_date))\n",
    "\n",
    "    if graph:\n",
    "        generate_end_report(portfolios, sim_start_date, sim_end_date)\n",
    "\n",
    "\n",
    "def simulate_stock(stock, sim_start_date, sim_end_date, tr_end_date, train_num_days, num_principal_components,\n",
    "                   num_pred_stocks, sparse, graph = True):\n",
    "    # Find correlated stock during training period\n",
    "    correlated_stock_ticker = list(corr_list_for_single_stock(stock, tr_end_date, train_num_days).keys())[1]\n",
    "\n",
    "    # Find synthetic stock portfolio during training period\n",
    "    synth_stocks = model_output_to_portfolio(\n",
    "        predict_portfolio(stock, num_principal_components, train_num_days, tr_end_date, num_pred_stocks, sparse),\n",
    "        sim_start_date)\n",
    "\n",
    "    synth_stock_portfolio = Portfolio(\"Synthetic\", sim_start_date, 0, starting_stocks=synth_stocks, synthetic=True)\n",
    "    correlated_stock_portfolio = Portfolio(correlated_stock_ticker, sim_start_date, 0, starting_stocks={\n",
    "        correlated_stock_ticker: Stock(correlated_stock_ticker, sim_start_date, 1)})\n",
    "    baseline_stock_portfolio = Portfolio(stock, sim_start_date, 0,\n",
    "                                         starting_stocks={stock: Stock(stock, sim_start_date, 1)}, baseline=True)\n",
    "\n",
    "    # ensure that the real stock is first in the portfolio\n",
    "    portfolios = get_normalized_portfolios(\n",
    "        [baseline_stock_portfolio, synth_stock_portfolio, correlated_stock_portfolio], sim_start_date)\n",
    "\n",
    "    run_simulation(sim_start_date, sim_end_date, portfolios, graph)\n",
    "    return get_correlations(portfolios)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAPLxAZTA': 0.5705627623418507, 'AAPLxSynthetic': 0.5164994633209425}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.5164994633209427}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.5275784262360692}\n",
      "{'AAPLxAZTA': 0.5705627623418488, 'AAPLxSynthetic': 0.5263579013771164}\n",
      "{'AAPLxAZTA': 0.5705627623418497, 'AAPLxSynthetic': 0.5334243431689748}\n",
      "{'AAPLxAZTA': 0.570562762341851, 'AAPLxSynthetic': 0.5312936788971386}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.5272930506332969}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.5254051902673854}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.6952352103611964}\n",
      "{'AAPLxAZTA': 0.5705627623418488, 'AAPLxSynthetic': 0.692960866109594}\n",
      "{'AAPLxAZTA': 0.5705627623418495, 'AAPLxSynthetic': 0.6936088616917377}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.6911082969650829}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.6680804500961536}\n",
      "{'AAPLxAZTA': 0.5705627623418507, 'AAPLxSynthetic': 0.6671186069485692}\n",
      "{'AAPLxAZTA': 0.5705627623418495, 'AAPLxSynthetic': 0.6754323191712048}\n",
      "{'AAPLxAZTA': 0.5705627623418491, 'AAPLxSynthetic': 0.6752737858963819}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.6945068341933132}\n",
      "{'AAPLxAZTA': 0.5705627623418491, 'AAPLxSynthetic': 0.6954863822556206}\n",
      "{'AAPLxAZTA': 0.5705627623418492, 'AAPLxSynthetic': 0.6899731857828352}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.6914867349284041}\n",
      "{'AAPLxAZTA': 0.5705627623418514, 'AAPLxSynthetic': 0.6990424005065159}\n",
      "{'AAPLxAZTA': 0.5705627623418495, 'AAPLxSynthetic': 0.7013664518477245}\n",
      "{'AAPLxAZTA': 0.5705627623418512, 'AAPLxSynthetic': 0.6841469137295972}\n",
      "{'AAPLxAZTA': 0.5705627623418492, 'AAPLxSynthetic': 0.6844871317549729}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.688608871985365}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.68873589241446}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.6995065007560668}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.6994773032729863}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7049100672339469}\n",
      "{'AAPLxAZTA': 0.5705627623418511, 'AAPLxSynthetic': 0.7052868808330163}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.7265636592062804}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.725799324191723}\n",
      "{'AAPLxAZTA': 0.5705627623418507, 'AAPLxSynthetic': 0.7270809908333241}\n",
      "{'AAPLxAZTA': 0.5705627623418511, 'AAPLxSynthetic': 0.7264863653256832}\n",
      "{'AAPLxAZTA': 0.5705627623418497, 'AAPLxSynthetic': 0.730216408484203}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7297273674027999}\n",
      "{'AAPLxAZTA': 0.5705627623418497, 'AAPLxSynthetic': 0.7307124420042684}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7301319166642122}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7285718192391167}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.7280177640852743}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.6992614860975932}\n",
      "{'AAPLxAZTA': 0.57056276234185, 'AAPLxSynthetic': 0.702237567856999}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7018236838102524}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.7044026873046026}\n",
      "{'AAPLxAZTA': 0.5705627623418508, 'AAPLxSynthetic': 0.6981910080750966}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7011158019013368}\n",
      "{'AAPLxAZTA': 0.5705627623418495, 'AAPLxSynthetic': 0.7119046512447563}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.7143180711864027}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.7238877552595193}\n",
      "{'AAPLxAZTA': 0.5705627623418508, 'AAPLxSynthetic': 0.7257286262255765}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7207178112887056}\n",
      "{'AAPLxAZTA': 0.570562762341851, 'AAPLxSynthetic': 0.7227673334295723}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.7203437024943726}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.7225570708469421}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7208045550276525}\n",
      "{'AAPLxAZTA': 0.5705627623418508, 'AAPLxSynthetic': 0.7228746768136145}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7208045048536789}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.7232716419823685}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.7207959375012454}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7233719130539359}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7208088933357019}\n",
      "{'AAPLxAZTA': 0.5705627623418489, 'AAPLxSynthetic': 0.7233416890552207}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7190689391548154}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7218081126164919}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.7191884938011522}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7219059755090121}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.7205454517025771}\n",
      "{'AAPLxAZTA': 0.5705627623418492, 'AAPLxSynthetic': 0.7230753017133604}\n",
      "{'AAPLxAZTA': 0.5705627623418495, 'AAPLxSynthetic': 0.7200085658934348}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7226729421305121}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7258864493077365}\n",
      "{'AAPLxAZTA': 0.5705627623418497, 'AAPLxSynthetic': 0.7279875185751501}\n",
      "{'AAPLxAZTA': 0.57056276234185, 'AAPLxSynthetic': 0.7242702173049149}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.7264431350026298}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7245654406334869}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.7266161265236629}\n",
      "{'AAPLxAZTA': 0.570562762341849, 'AAPLxSynthetic': 0.7234145777966429}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7255862302026803}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7227365683143503}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.72495461943837}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.726132261023386}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7281449465135946}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7256464301443228}\n",
      "{'AAPLxAZTA': 0.5705627623418507, 'AAPLxSynthetic': 0.7278010436284483}\n",
      "{'AAPLxAZTA': 0.5705627623418509, 'AAPLxSynthetic': 0.7241614337272719}\n",
      "{'AAPLxAZTA': 0.57056276234185, 'AAPLxSynthetic': 0.7262835273982569}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.7246461746647171}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.7274625398673354}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7258092327559118}\n",
      "{'AAPLxAZTA': 0.5705627623418518, 'AAPLxSynthetic': 0.7285967286350005}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.7254270188695711}\n",
      "{'AAPLxAZTA': 0.570562762341851, 'AAPLxSynthetic': 0.7282533910672766}\n",
      "{'AAPLxAZTA': 0.570562762341851, 'AAPLxSynthetic': 0.7238072774875004}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.7266507471770821}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7244221470964729}\n",
      "{'AAPLxAZTA': 0.5705627623418488, 'AAPLxSynthetic': 0.7272717563012964}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.5164994633209427}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.5164994633209427}\n",
      "{'AAPLxAZTA': 0.5705627623418497, 'AAPLxSynthetic': 0.6288849545434698}\n",
      "{'AAPLxAZTA': 0.5705627623418508, 'AAPLxSynthetic': 0.6291778374913323}\n",
      "{'AAPLxAZTA': 0.5705627623418509, 'AAPLxSynthetic': 0.7146877389407363}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.7142015871975746}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7136071920027287}\n",
      "{'AAPLxAZTA': 0.5705627623418507, 'AAPLxSynthetic': 0.713176950993873}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7254599023575519}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7248525550556537}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7245634638218833}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7240497401882623}\n",
      "{'AAPLxAZTA': 0.570562762341849, 'AAPLxSynthetic': 0.7191414694760327}\n",
      "{'AAPLxAZTA': 0.5705627623418508, 'AAPLxSynthetic': 0.7185662825224798}\n",
      "{'AAPLxAZTA': 0.57056276234185, 'AAPLxSynthetic': 0.6664253396606592}\n",
      "{'AAPLxAZTA': 0.570562762341851, 'AAPLxSynthetic': 0.6661784330690312}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.667145096178307}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.6668924504763194}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.6930885158199863}\n",
      "{'AAPLxAZTA': 0.5705627623418505, 'AAPLxSynthetic': 0.6929992512824469}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.6932838748908071}\n",
      "{'AAPLxAZTA': 0.5705627623418495, 'AAPLxSynthetic': 0.6932369255273683}\n",
      "{'AAPLxAZTA': 0.5705627623418513, 'AAPLxSynthetic': 0.7077773916829165}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.7075317473462359}\n",
      "{'AAPLxAZTA': 0.5705627623418495, 'AAPLxSynthetic': 0.72140832627036}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7210759459573947}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.7220013314607753}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7216601467999432}\n",
      "{'AAPLxAZTA': 0.5705627623418514, 'AAPLxSynthetic': 0.7170767458741628}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7166613458425483}\n",
      "{'AAPLxAZTA': 0.5705627623418507, 'AAPLxSynthetic': 0.7165171710977096}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7160303144042}\n",
      "{'AAPLxAZTA': 0.5705627623418511, 'AAPLxSynthetic': 0.7275081268779916}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.7271907990107896}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7280793460276175}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7277687477729842}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7296117168948218}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.7293110758151142}\n",
      "{'AAPLxAZTA': 0.5705627623418504, 'AAPLxSynthetic': 0.729611741307189}\n",
      "{'AAPLxAZTA': 0.5705627623418497, 'AAPLxSynthetic': 0.7295263655659517}\n",
      "{'AAPLxAZTA': 0.5705627623418508, 'AAPLxSynthetic': 0.7359665140106036}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7359920032309644}\n",
      "{'AAPLxAZTA': 0.5705627623418509, 'AAPLxSynthetic': 0.7467058950719629}\n",
      "{'AAPLxAZTA': 0.5705627623418494, 'AAPLxSynthetic': 0.7467624825181264}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7572117579309573}\n",
      "{'AAPLxAZTA': 0.57056276234185, 'AAPLxSynthetic': 0.7572386101365046}\n",
      "{'AAPLxAZTA': 0.5705627623418492, 'AAPLxSynthetic': 0.7569448563364297}\n",
      "{'AAPLxAZTA': 0.5705627623418497, 'AAPLxSynthetic': 0.7570181394796905}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7597852510362887}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.7597932102294491}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7593295369814963}\n",
      "{'AAPLxAZTA': 0.5705627623418499, 'AAPLxSynthetic': 0.7593054683320556}\n",
      "{'AAPLxAZTA': 0.5705627623418502, 'AAPLxSynthetic': 0.7586831861376202}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7586872154404609}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.757331284707968}\n",
      "{'AAPLxAZTA': 0.5705627623418507, 'AAPLxSynthetic': 0.7572091606481708}\n",
      "{'AAPLxAZTA': 0.5705627623418501, 'AAPLxSynthetic': 0.7491306849879729}\n",
      "{'AAPLxAZTA': 0.5705627623418503, 'AAPLxSynthetic': 0.7489947760782342}\n",
      "{'AAPLxAZTA': 0.5705627623418493, 'AAPLxSynthetic': 0.7498054915281972}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7496678471373319}\n",
      "{'AAPLxAZTA': 0.5705627623418498, 'AAPLxSynthetic': 0.7492359530901982}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [119]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m num_pred_stocks \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m50\u001B[39m):\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m sparse \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m]:\n\u001B[0;32m---> 16\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[43msimulate_stock\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAAPL\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_start_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_start_date\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_end_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_train_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_principal_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_pred_stocks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m)\n",
      "Input \u001B[0;32mIn [117]\u001B[0m, in \u001B[0;36msimulate_stock\u001B[0;34m(stock, sim_start_date, sim_end_date, tr_end_date, train_num_days, num_principal_components, num_pred_stocks, sparse, graph)\u001B[0m\n\u001B[1;32m     45\u001B[0m correlated_stock_ticker \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(corr_list_for_single_stock(stock, tr_end_date, train_num_days)\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# Find synthetic stock portfolio during training period\u001B[39;00m\n\u001B[1;32m     48\u001B[0m synth_stocks \u001B[38;5;241m=\u001B[39m model_output_to_portfolio(\n\u001B[0;32m---> 49\u001B[0m     \u001B[43mpredict_portfolio\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_principal_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_num_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtr_end_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_pred_stocks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     50\u001B[0m     sim_start_date)\n\u001B[1;32m     52\u001B[0m synth_stock_portfolio \u001B[38;5;241m=\u001B[39m Portfolio(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSynthetic\u001B[39m\u001B[38;5;124m\"\u001B[39m, sim_start_date, \u001B[38;5;241m0\u001B[39m, starting_stocks\u001B[38;5;241m=\u001B[39msynth_stocks, synthetic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     53\u001B[0m correlated_stock_portfolio \u001B[38;5;241m=\u001B[39m Portfolio(correlated_stock_ticker, sim_start_date, \u001B[38;5;241m0\u001B[39m, starting_stocks\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m     54\u001B[0m     correlated_stock_ticker: Stock(correlated_stock_ticker, sim_start_date, \u001B[38;5;241m1\u001B[39m)})\n",
      "Input \u001B[0;32mIn [114]\u001B[0m, in \u001B[0;36mpredict_portfolio\u001B[0;34m(pred_stock, n_components, n_days, end_date, n_stocks, sparse)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_portfolio\u001B[39m(pred_stock, n_components, n_days, end_date, n_stocks, sparse):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"Constructs a portfolio using the given hyperparameters\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    :param pred_stock: The stock to predict\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    :param n_components: The number of principal components the model should use\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m    :param sparse: Whether PCA should be sparse or not\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m     correlation_list \u001B[38;5;241m=\u001B[39m \u001B[43mcorr_list_for_single_stock\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAAPL\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_days\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;66;03m# Get price history datasets\u001B[39;00m\n\u001B[1;32m     13\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m get_datasets(correlation_list, pred_stock, n_stocks, end_date, n_days)\n",
      "Input \u001B[0;32mIn [76]\u001B[0m, in \u001B[0;36mcorr_list_for_single_stock\u001B[0;34m(ticker, end_date, recent_days)\u001B[0m\n\u001B[1;32m     56\u001B[0m correlation_matrix \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(x_labels)):\n\u001B[0;32m---> 59\u001B[0m     correlation_matrix[x_labels[l]] \u001B[38;5;241m=\u001B[39m ticker_price_history\u001B[38;5;241m.\u001B[39mcorr(\u001B[43msptm_price_history\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43ml\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mClose\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpct_change\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39miloc[end_date\u001B[38;5;241m-\u001B[39mrecent_days:end_date])\n\u001B[1;32m     60\u001B[0m correlation_matrix \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m( \u001B[38;5;28msorted\u001B[39m(correlation_matrix\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39moperator\u001B[38;5;241m.\u001B[39mitemgetter(\u001B[38;5;241m1\u001B[39m),reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m correlation_matrix\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/generic.py:10366\u001B[0m, in \u001B[0;36mNDFrame.pct_change\u001B[0;34m(self, periods, fill_method, limit, freq, **kwargs)\u001B[0m\n\u001B[1;32m  10364\u001B[0m shifted \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mshift(periods\u001B[38;5;241m=\u001B[39mperiods, freq\u001B[38;5;241m=\u001B[39mfreq, axis\u001B[38;5;241m=\u001B[39maxis, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m  10365\u001B[0m \u001B[38;5;66;03m# Unsupported left operand type for / (\"NDFrameT\")\u001B[39;00m\n\u001B[0;32m> 10366\u001B[0m rs \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mshifted\u001B[49m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m  \u001B[38;5;66;03m# type: ignore[operator]\u001B[39;00m\n\u001B[1;32m  10367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m freq \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m  10368\u001B[0m     \u001B[38;5;66;03m# Shift method is implemented differently when freq is not None\u001B[39;00m\n\u001B[1;32m  10369\u001B[0m     \u001B[38;5;66;03m# We want to restore the original index\u001B[39;00m\n\u001B[1;32m  10370\u001B[0m     rs \u001B[38;5;241m=\u001B[39m rs\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;241m~\u001B[39mrs\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mduplicated()]\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/ops/common.py:70\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     66\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     68\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/arraylike.py:124\u001B[0m, in \u001B[0;36mOpsMixin.__truediv__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__truediv__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__truediv__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m--> 124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtruediv\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/series.py:5639\u001B[0m, in \u001B[0;36mSeries._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   5637\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_arith_method\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, op):\n\u001B[1;32m   5638\u001B[0m     \u001B[38;5;28mself\u001B[39m, other \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39malign_method_SERIES(\u001B[38;5;28mself\u001B[39m, other)\n\u001B[0;32m-> 5639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIndexOpsMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/base.py:1297\u001B[0m, in \u001B[0;36mIndexOpsMixin._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   1295\u001B[0m     result \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39marithmetic_op(lvalues, rvalues, op)\n\u001B[0;32m-> 1297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mres_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/series.py:3017\u001B[0m, in \u001B[0;36mSeries._construct_result\u001B[0;34m(self, result, name)\u001B[0m\n\u001B[1;32m   3013\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (res1, res2)\n\u001B[1;32m   3015\u001B[0m \u001B[38;5;66;03m# We do not pass dtype to ensure that the Series constructor\u001B[39;00m\n\u001B[1;32m   3016\u001B[0m \u001B[38;5;66;03m#  does inference in the case where `result` has object-dtype.\u001B[39;00m\n\u001B[0;32m-> 3017\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_constructor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3018\u001B[0m out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   3020\u001B[0m \u001B[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001B[39;00m\n\u001B[1;32m   3021\u001B[0m \u001B[38;5;66;03m#  would set it back to self.name\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/series.py:365\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    361\u001B[0m         index \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mindex\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 365\u001B[0m     name \u001B[38;5;241m=\u001B[39m \u001B[43mibase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_extract_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_empty_data(data) \u001B[38;5;129;01mand\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    368\u001B[0m         \u001B[38;5;66;03m# gh-17261\u001B[39;00m\n\u001B[1;32m    369\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    370\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe default dtype for empty Series will be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m instead \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    371\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat64\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in a future version. Specify a dtype explicitly \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    374\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    375\u001B[0m         )\n",
      "File \u001B[0;32m~/Documents/GitHub/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:7086\u001B[0m, in \u001B[0;36mmaybe_extract_name\u001B[0;34m(name, obj, cls)\u001B[0m\n\u001B[1;32m   7082\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmaybe_extract_name\u001B[39m(name, obj, \u001B[38;5;28mcls\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Hashable:\n\u001B[1;32m   7083\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   7084\u001B[0m \u001B[38;5;124;03m    If no name is passed, then extract it from data, validating hashability.\u001B[39;00m\n\u001B[1;32m   7085\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 7086\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mIndex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mABCSeries\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   7087\u001B[0m         \u001B[38;5;66;03m# Note we don't just check for \"name\" attribute since that would\u001B[39;00m\n\u001B[1;32m   7088\u001B[0m         \u001B[38;5;66;03m#  pick up e.g. dtype.name\u001B[39;00m\n\u001B[1;32m   7089\u001B[0m         name \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m   7091\u001B[0m     \u001B[38;5;66;03m# GH#29069\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# def simulate_stock(stock: {__eq__},\n",
    "#                    sim_start_date: Any,\n",
    "#                    sim_end_date: {__sub__},\n",
    "#                    tr_end_date: {__sub__},\n",
    "#                    train_num_days: Any,\n",
    "#                    num_principal_components: Any,\n",
    "#                    num_pred_stocks: Any,\n",
    "#                    sparse: Any) -> None\n",
    "#                    graph: bool = True) -> None\n",
    "#simulate_stock('AAPL', test_start_date, test_start_date + 20, train_end_date, 120, 2, 10, False, graph = True)\n",
    "\n",
    "for num_principal_components in range(1, 10):\n",
    "    for num_train_days in [30, 60, 90, 120, 150, 180, 360]:\n",
    "        for num_pred_stocks in range(2, 50):\n",
    "            for sparse in [True, False]:\n",
    "                print(simulate_stock('AAPL', test_start_date, test_start_date+30, train_end_date, num_train_days, num_principal_components, num_pred_stocks, sparse, graph=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "#pf.create_returns_tear_sheet(returns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}