{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A Hybrid Learning Approach to Synthetic Position Construction for Tax Loss Harvesting"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generation of Synthetic Positions Using Hybrid Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "import statsmodels.api as sm\n",
    "import operator\n",
    "from deprecated import deprecated\n",
    "\n",
    "corr_matrix_file_path = \"pickles/corr_matrix.obj\"\n",
    "x_labels_file_path = \"pickles/X_labels.obj\"\n",
    "sptm_comp_file_path = \"pickles/sptm_composition.obj\"\n",
    "sptm_price_file_path = \"pickles/sptm_price.obj\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "# Composition data from pickle\n",
    "sptm_comp_file = open(sptm_comp_file_path, 'rb')\n",
    "sptm_composition = pickle.load(sptm_comp_file)\n",
    "sptm_comp_file.close()\n",
    "\n",
    "# Price history downloaded from Yahoo Finance and stored in pickle\n",
    "sptm_price_file = open(sptm_price_file_path, 'rb')\n",
    "sptm_price_history = pickle.load(sptm_price_file)\n",
    "sptm_price_file.close()\n",
    "\n",
    "all_tickers = sptm_composition.keys()\n",
    "\n",
    "# Gets a list of all valid trading dates\n",
    "all_dates = sptm_price_history[list(all_tickers)[0]].axes[0].values\n",
    "dates = pd.DatetimeIndex(data=all_dates)\n",
    "current_date = all_dates[0]\n",
    "\n",
    "# 80/20 Test/Train Split\n",
    "# Data Range: 2015-01-02 - 2020-08-10\n",
    "# Testing Range: 2020-08-11 - 2021-12-31\n",
    "train_start_date = 0\n",
    "train_end_date = 1410\n",
    "test_start_date = 1411\n",
    "test_end_date = 1762\n",
    "\n",
    "# Choose how many days should be used to validate the hyperparameters\n",
    "num_validation_days = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding Highly Correlated Stocks\n",
    "#### Use the *do_corr_matrix_regen* variable to tell the code to generate the correlation matrix, else it will load it from a pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "num_stocks = len(all_tickers)\n",
    "\n",
    "\n",
    "@deprecated(reason=\"Switched to generating singular correlation lists on the fly\")\n",
    "def regenerate_corr_matrix(end_date, recent_days):\n",
    "    \"\"\"Calculates the correlation between every stock's percent time series\n",
    "    :param end_date: The last date for which data should be used to generate the correlation matrix\n",
    "    :param recent_days: How many days of price history should be used to calculate the correlation matrix\n",
    "    \"\"\"\n",
    "    x_vars = []\n",
    "    x_labels = []\n",
    "\n",
    "    for ticker in all_tickers:\n",
    "        x_vars.append(sptm_price_history[ticker].Close.pct_change().iloc[end_date - recent_days:end_date])\n",
    "        x_labels.append(ticker)\n",
    "\n",
    "    correlation_matrix = [[0 for _ in range(0, num_stocks)] for _ in range(0, num_stocks)]\n",
    "\n",
    "    for l in range(0, num_stocks):\n",
    "        for m in range(0, num_stocks):\n",
    "            correlation_matrix[l][m] = x_vars[l].corr(x_vars[m])\n",
    "    correlation_matrix = pd.DataFrame(correlation_matrix, columns=x_labels[0:num_stocks])\n",
    "\n",
    "    correlation_matrix_file = open(corr_matrix_file_path, 'wb')\n",
    "    pickle.dump(correlation_matrix, correlation_matrix_file)\n",
    "    correlation_matrix_file.close()\n",
    "\n",
    "    x_labels_file = open(x_labels_file_path, 'wb')\n",
    "    pickle.dump(x_labels, x_labels_file)\n",
    "    x_labels_file.close()\n",
    "\n",
    "\n",
    "@deprecated(reason=\"Switched to generating singular correlation lists on the fly\")\n",
    "def load_corr_matrix():\n",
    "    \"\"\"Loads correlation matrix and labels from pickles\n",
    "    :returns: [correlation_matrix, x_labels]\n",
    "    \"\"\"\n",
    "    # Covariance Matrix from pickle\n",
    "    corr_matrix_file = open(corr_matrix_file_path, 'rb')\n",
    "    correlation_matrix = pickle.load(corr_matrix_file)\n",
    "    corr_matrix_file.close()\n",
    "\n",
    "    # X_Labels from pickle\n",
    "    x_labels_file = open(x_labels_file_path, 'rb')\n",
    "    x_labels = pickle.load(x_labels_file)\n",
    "    x_labels_file.close()\n",
    "\n",
    "    return correlation_matrix, x_labels\n",
    "\n",
    "\n",
    "def corr_list_for_single_stock(ticker, end_date, recent_days):\n",
    "    x_labels = []\n",
    "\n",
    "    ticker_price_history = sptm_price_history[ticker].Close.pct_change().iloc[end_date - recent_days:end_date]\n",
    "\n",
    "    for tickers in sptm_price_history.keys():\n",
    "        x_labels.append(tickers)\n",
    "\n",
    "    correlation_matrix = {}\n",
    "\n",
    "    for l in range(0, len(x_labels)):\n",
    "        correlation_matrix[x_labels[l]] = ticker_price_history.corr(\n",
    "            sptm_price_history[x_labels[l]].Close.pct_change().iloc[end_date - recent_days:end_date])\n",
    "    correlation_matrix = dict(sorted(correlation_matrix.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "    return correlation_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "def filter_substantially_similar_securities(ticker, series, additional_stocks=None):\n",
    "    \"\"\"Filters out the stocks you cannot buy because of a wash sale\n",
    "    :param series: The series of correlated stocks that should be filtered\n",
    "    :param ticker: Ticker to filter out securities for\n",
    "    :param additional_stocks: Any additional stocks you want to filter out (default = None)\n",
    "    \"\"\"\n",
    "    if additional_stocks is None:\n",
    "        additional_stocks = []\n",
    "\n",
    "    # Handles Google having both GOOG and GOOGL in the dataset\n",
    "    if ticker == \"GOOG\" or ticker:\n",
    "        additional_stocks.append(\"GOOG\")\n",
    "        additional_stocks.append(\"GOOGL\")\n",
    "\n",
    "    additional_stocks.append(ticker)\n",
    "\n",
    "    for remove_stock in additional_stocks:\n",
    "        # for r_stock in remove_stock:\n",
    "        if remove_stock in series:\n",
    "            series.pop(series.index(remove_stock))\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def find_top_correlated_stocks(correlation_list, ticker, n):\n",
    "    \"\"\"Finds the top n stocks correlated with a given stock\n",
    "    :param correlation_list: The correlation list to get the top correlated stocks from\n",
    "    :param n: the number of correlated stocks to return\n",
    "    :param ticker: The ticker for which correlated stocks should be found\n",
    "    :returns: A list (sorted by most correlation) of correlated stocks\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_correlations = filter_substantially_similar_securities(ticker, list(correlation_list.keys()))\n",
    "\n",
    "    return filtered_correlations[:n]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Principle Component Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "def get_price_histories_dataframe(stocks, target_stock, end_date, recent_days):\n",
    "    \"\"\"Compiles a DataFrame with the price histories of the specified stocks\n",
    "    :param target_stock: The stock for which the dataset should be created\n",
    "    :param stocks: The stocks to include in the DataFrame\n",
    "    :param end_date: The last date for which data should be used to get the price history\n",
    "    :param recent_days: How many days of price history should be fetched\n",
    "    :returns: (Features DataFrame, Target DataFrame)\"\"\"\n",
    "    d = {}\n",
    "    for correlated_stock in stocks:\n",
    "        d[correlated_stock] = sptm_price_history[correlated_stock].Close.values[end_date - recent_days:end_date]\n",
    "    target = pd.DataFrame(\n",
    "        {target_stock: sptm_price_history[target_stock].Close.values[end_date - recent_days:end_date]})\n",
    "    return pd.DataFrame(data=d), target\n",
    "\n",
    "\n",
    "def get_datasets(correlation_list, target_stock, n, end_date, recent_days):\n",
    "    \"\"\"Compiles the necessary datasets for PCA. One with the price history of the features, and one with the price history of the target\n",
    "    :param correlation_list: The correlation list to get the top correlated stocks from\n",
    "    :param target_stock: The stock for which the dataset should be created\n",
    "    :param n: the number of datasets to get\n",
    "    :param end_date: The last date for which data should be used to get the price history\n",
    "    :param recent_days: How many days of price history should be fetched\n",
    "    :returns: (x, y) where x and y are DataFrames\n",
    "    \"\"\"\n",
    "    corr_stocks = find_top_correlated_stocks(correlation_list, target_stock, n)\n",
    "    return get_price_histories_dataframe(corr_stocks, target_stock, end_date, recent_days)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "outputs": [],
   "source": [
    "def predict_portfolio(pred_stock, n_components, n_days, end_date, n_stocks, is_sparse, regression_only = False):\n",
    "    \"\"\"Constructs a portfolio using the given hyperparameters\n",
    "    :param regression_only: Do not perform any PCA\n",
    "    :param pred_stock: The stock to predict\n",
    "    :param n_components: The number of principal components the model should use\n",
    "    :param n_days: The number of days of data the model should consider\n",
    "    :param end_date: The last date of data the model should use\n",
    "    :param n_stocks: The number of stocks to be used by principal component analysis\n",
    "    :param is_sparse: Whether PCA should be sparse or not\n",
    "    \"\"\"\n",
    "    correlation_list = corr_list_for_single_stock(pred_stock, end_date, n_days)\n",
    "\n",
    "    # Get price history datasets\n",
    "    x, y = get_datasets(correlation_list, pred_stock, n_stocks, end_date, n_days)\n",
    "\n",
    "    # Standardize the features\n",
    "    X = StandardScaler().fit_transform(x)\n",
    "\n",
    "    # Do the PCA\n",
    "    if is_sparse:\n",
    "        pca = SparsePCA(n_components=n_components)\n",
    "    else:\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "    principal_components = pca.fit_transform(X)\n",
    "    principal_df = pd.DataFrame(data=principal_components, columns=[\"PC \" + str(g) for g in range(0, n_components)])\n",
    "\n",
    "    # Linear Regression of principal components\n",
    "    sm.add_constant(principal_df)\n",
    "    if regression_only:\n",
    "        model = sm.OLS(y, x).fit()\n",
    "        synthetic_position = {}\n",
    "        for param in model.params.index:\n",
    "            synthetic_position[param] = model.params[param]\n",
    "        return synthetic_position\n",
    "\n",
    "    model = sm.OLS(y, principal_df).fit()\n",
    "    #print(principal_df)\n",
    "    #print(y)\n",
    "    #print(model.summary())\n",
    "\n",
    "    #print(model.summary())\n",
    "\n",
    "\n",
    "    loadings = pd.DataFrame(pca.components_.T, index=x.columns)\n",
    "    loadings_dict = {stock: [] for stock in loadings[0].index.values}\n",
    "\n",
    "    #print(loadings)\n",
    "\n",
    "    for c_stock in loadings[0].index.values:\n",
    "        for pc in range(0, n_components):\n",
    "            loadings_dict[c_stock].append(loadings[pc][c_stock])\n",
    "\n",
    "    synthetic_position = {}\n",
    "\n",
    "    # for c_stock in model.params.index.values:\n",
    "    #     if model.pvalues[c_stock]<0.05 and model.params[c_stock]>0:\n",
    "    #         print(\"adding c_stock\")\n",
    "    #         synthetic_position[c_stock] = model.params[c_stock]\n",
    "    # return synthetic_position\n",
    "\n",
    "    if n_components==1:\n",
    "        for c_stock in loadings_dict.keys():\n",
    "            synthetic_position[c_stock] = loadings_dict[c_stock][0]\n",
    "        return synthetic_position\n",
    "\n",
    "    for c_stock in loadings_dict.keys():\n",
    "        quantity = 0\n",
    "        for pc in range(0, n_components):\n",
    "            quantity += model.params[pc] * loadings_dict[c_stock][pc]\n",
    "        if quantity > 0:\n",
    "            synthetic_position[c_stock] = quantity\n",
    "    #print(synthetic_position)\n",
    "    return synthetic_position"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [],
   "source": [
    "# sportfolios = simulate_stock('AAPL', test_start_date, test_start_date+30, train_end_date, 360, 2, 10, True, regression_only = True, graph=True)\n",
    "# print(get_stats(sportfolios))\n",
    "\n",
    "\n",
    "#when training days are higher, the p values are higher, but the model gets less MSE\n",
    "#for regression only take into account how you can only use positive values, which is mostly solved by PCA (why?)\n",
    "#if you wanted to be more accurate, then instead of cancelling the entire replacement if a stock is on the wash asale list, you can just recalculate without that stock (or just pass the wash sale list to the filterer to begin with)\n",
    "#TODO above"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [],
   "source": [
    "def hybrid_learning_replace(ticker, cur_date) -> {}:\n",
    "    \"\"\"Determines which stocks to buy to emulate the performance of another\n",
    "    :param cur_date: The date on which to find replacements\n",
    "    :param ticker: The stock for which a synthetic position should be calculated\n",
    "    :returns: Dictionary of replacement tickers and their quantities\n",
    "    \"\"\"\n",
    "    synthetic_position = predict_portfolio(ticker, 2, 90, cur_date, 15, True)\n",
    "    return synthetic_position\n",
    "    #TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stock Market Backtester"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to run this simulator with different stocks and/or generate a new starting portfolio, do the following:\n",
    "1. Create a CSV file with the format: Ticker, Quantity\n",
    "2. Run **csvToComp.py** to generate text you can paste in as the *snp_composition* variable in **compToPickle.py**\n",
    "3. Run **compToPickle.py**\n",
    "4. Adjust the date range in **yfToPickle.py**\n",
    "5. Run **yfToPickle.py**, which will take a while, since it is downloading all of the price histories from Yahoo Finance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyfolio as pf  #install using  pip3 install git+https://github.com/quantopian/pyfolio\n",
    "from enum import Enum\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "snp_comp_file_path = \"pickles/snp_composition.obj\"\n",
    "snp_price_file_path = \"pickles/snp_price.obj\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "# Composition data from pickle\n",
    "snp_comp_file = open(snp_comp_file_path, 'rb')\n",
    "snp_composition = pickle.load(snp_comp_file)\n",
    "snp_comp_file.close()\n",
    "\n",
    "# Price history downloaded from Yahoo Finance and stored in pickle\n",
    "snp_price_file = open(sptm_price_file_path, 'rb')\n",
    "price_history = pickle.load(snp_price_file)\n",
    "snp_price_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# Gets a list of all valid trading dates\n",
    "all_dates = price_history[list(all_tickers)[0]].axes[0].values\n",
    "dates = pd.DatetimeIndex(data=all_dates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "outputs": [],
   "source": [
    "def get_stock_price(ticker, day, time) -> float:\n",
    "    \"\"\"Retrieves the closing price of a stock on a given date\n",
    "    :param ticker: stock for which to retrieve the value\n",
    "    :param day: date on which to retrieve the value\n",
    "    :param time of day to calculate the value, either Time.OPEN or Time.CLOSE\n",
    "    \"\"\"\n",
    "    if time == Time.OPEN:\n",
    "        return round(price_history[ticker].Open[day], 2)\n",
    "    elif time == Time.CLOSE:\n",
    "        return round(price_history[ticker].Close[day], 2)\n",
    "\n",
    "\n",
    "class Time(Enum):\n",
    "    OPEN = 0\n",
    "    CLOSE = 1\n",
    "\n",
    "class ReplacementGroup:\n",
    "    def __init__(self, stock_list, stock):\n",
    "        self.stock_list = stock_list\n",
    "        self.counter = 0\n",
    "        self.stock = stock\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, ticker, cur_date, q=0):\n",
    "        \"\"\"Creates an object representing an owned stock\n",
    "        :param ticker: The stock's ticker symbol\n",
    "        :param q: How much of this stock is owned (this should only be used when constructing initial stock portfolios, as it essentially creates stock for free)\n",
    "        \"\"\"\n",
    "        self.ticker = ticker\n",
    "        self.quantity = q\n",
    "        self.avg_cost = get_stock_price(self.ticker, cur_date, Time.OPEN)\n",
    "\n",
    "    def buy(self, quantity, day_price):\n",
    "        \"\"\"Simulates a portfolio acquiring new stock\n",
    "        :param quantity: The amount of new stock to acquire\n",
    "        :param day_price: The price of the stock on the day of acquisition\n",
    "        \"\"\"\n",
    "        previously_owned = self.quantity\n",
    "        self.quantity += quantity\n",
    "        if previously_owned==0:\n",
    "            self.avg_cost=day_price\n",
    "            return\n",
    "        self.avg_cost += (previously_owned * self.avg_cost + quantity * day_price) / self.quantity\n",
    "\n",
    "    def sell(self, q, day_price):\n",
    "        \"\"\"Simulates a portfolio selling a stock\n",
    "        :param q: The amount of new stock to sell\n",
    "        :param day_price: The price of the stock on the day of acquisition\n",
    "        \"\"\"\n",
    "        previously_owned = self.quantity\n",
    "        self.quantity -= q\n",
    "        if self.quantity==0:\n",
    "            self.avg_cost=0\n",
    "            return\n",
    "        self.avg_cost -= (previously_owned * self.avg_cost - q * day_price) / self.quantity\n",
    "\n",
    "    def sell_all(self):\n",
    "        \"\"\"Simulates selling all of a stock\n",
    "        \"\"\"\n",
    "        self.quantity = 0\n",
    "        self.avg_cost = 0\n",
    "\n",
    "    def get_pct_change(self, change_date):\n",
    "        \"\"\"Gets the percent change of the stock based on the average cost\n",
    "        \"\"\"\n",
    "        change = self.get_change(change_date)\n",
    "        return 100 * (change / self.avg_cost)\n",
    "\n",
    "    def get_change(self, change_date) -> float:\n",
    "        \"\"\"Gets the difference between the stock's average purchase price and its current price\n",
    "        :returns: float\n",
    "        \"\"\"\n",
    "        current_price = get_stock_price(self.ticker, change_date, Time.OPEN)\n",
    "        return current_price - self.avg_cost\n",
    "\n",
    "\n",
    "class Portfolio:\n",
    "    def __init__(self, name, sim_start_date, starting_cash_balance: float = 1000000, starting_stocks=None,\n",
    "                 baseline=False, synthetic=False, replacement=False):\n",
    "        \"\"\"Creates a new portfolio\n",
    "        :param starting_cash_balance: The amount of cash the portfolio should start with (default 100,000.0)\n",
    "        :param starting_stocks: A dictionary containing the stocks the portfolio should begin with {'Ticker': Stock Object} (default is no starting stocks)\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        if starting_stocks is None:\n",
    "            starting_stocks = {}\n",
    "        self.stocks = starting_stocks\n",
    "        self.cash_balance = starting_cash_balance\n",
    "        self.value = 0\n",
    "        self.calculate_value(Time.OPEN, sim_start_date)\n",
    "        self.price_history = {}\n",
    "        self.closing_prices = []\n",
    "        self.returns = None\n",
    "        self.wash_sale_list = {}\n",
    "        self.baseline = baseline\n",
    "        self.synthetic = synthetic\n",
    "        self.replacement = replacement\n",
    "        self.diff = []\n",
    "        self.replacement_groups = []\n",
    "        self.do_not_replace_list = []\n",
    "\n",
    "    def calculate_value(self, time, calc_date):\n",
    "        \"\"\"Calculates the value of the portfolio based on the close of the global current date\n",
    "        :param calc_date: The date on whcih to calculate the value\n",
    "        :param time of day to calculate the value, either Time.OPEN or Time.CLOSE\n",
    "        \"\"\"\n",
    "        self.calculate_value_date(calc_date, time)\n",
    "\n",
    "    def calculate_value_date(self, c_day, time=Time.OPEN):\n",
    "        \"\"\"Calculates the value of the portfolio based on a specified date\n",
    "        :param c_day: the date on which the portfolio's value should be calculated\n",
    "        :param time of day to calculate the value, either Time.OPEN or (default) Time.CLOSE\n",
    "        \"\"\"\n",
    "\n",
    "        self.value = self.cash_balance\n",
    "        for stock in self.stocks.keys():\n",
    "            self.value += get_stock_price(stock, c_day, time) * self.stocks[stock].quantity\n",
    "\n",
    "        return self.value\n",
    "\n",
    "    def update_wash_sale_list(self):\n",
    "        \"\"\"Increments the counter for every item in the wash sale list and removes an item if the counter is >30\n",
    "        \"\"\"\n",
    "        remove_from_list = []\n",
    "        for wash_stock in self.wash_sale_list.keys():\n",
    "            self.wash_sale_list[wash_stock] += 1\n",
    "            if self.wash_sale_list[wash_stock] > 30:\n",
    "                remove_from_list.append(wash_stock)\n",
    "\n",
    "        for to_remove in remove_from_list:\n",
    "            self.wash_sale_list.pop(to_remove)\n",
    "\n",
    "    def update_replacement_groups(self, update_date):\n",
    "        rgs_to_delete = []\n",
    "        for rg in self.replacement_groups:\n",
    "            rg.counter+=1\n",
    "            if rg.counter >30:\n",
    "                starting_balance = self.cash_balance\n",
    "                for s in rg.stock_list:\n",
    "                    if s not in self.wash_sale_list:\n",
    "                        if s in self.do_not_replace_list:\n",
    "                            self.do_not_replace_list.pop(self.do_not_replace_list.index(s))\n",
    "                        self.sell_stock(s, update_date, rg.stock_list[s], sell_all=True)\n",
    "                rgs_to_delete.append(rg)\n",
    "                # print(\"unreplacing \"+rg.stock+\" on \"+str(update_date))\n",
    "                self.buy_stock(rg.stock, update_date, (self.cash_balance-starting_balance)/get_stock_price(rg.stock, update_date, Time.OPEN), amap=True)\n",
    "                # for s in self.stocks:\n",
    "                #     print(s+\": \"+str(self.stocks[s].quantity))\n",
    "\n",
    "        for rg in rgs_to_delete:\n",
    "            self.replacement_groups.pop(self.replacement_groups.index(rg))\n",
    "\n",
    "\n",
    "\n",
    "    def begin_day(self, date_to_begin):\n",
    "        \"\"\"Calculates the starting value of the day and updates the wash sale list\n",
    "        \"\"\"\n",
    "        self.calculate_value(Time.OPEN, date_to_begin)\n",
    "        self.update_wash_sale_list()\n",
    "        self.update_replacement_groups(date_to_begin)\n",
    "\n",
    "    def end_day(self, date_to_record):\n",
    "        \"\"\"\"Calculates the day's closing value and adds it to a list\n",
    "        :param date_to_record: The date associated with the ending day\n",
    "        \"\"\"\n",
    "        self.calculate_value(Time.OPEN, date_to_record)\n",
    "        self.price_history[date_to_record] = self.value\n",
    "        self.closing_prices.append(self.value)\n",
    "\n",
    "    def end_simulation(self, start_date_index, end_date_index):\n",
    "        \"\"\"Creates a Pandas Series of percent change of closing values and returns it\n",
    "        :param start_date_index: The index of the day that the simulation started\n",
    "        :param end_date_index: The index of the day that the simulation ended\n",
    "        \"\"\"\n",
    "        self.returns = pd.Series(data=self.closing_prices, index=dates[start_date_index:end_date_index]).pct_change()\n",
    "        return self.returns\n",
    "\n",
    "    def does_own_stock(self, ticker) -> bool:\n",
    "        \"\"\"Reports whether this portfolio contains a given stock\n",
    "        :param ticker: The stock to search for\n",
    "        \"\"\"\n",
    "        return ticker in self.stocks.keys()\n",
    "\n",
    "    def buy_stock(self, ticker, buy_date, quantity_to_buy, amap= False):\n",
    "        \"\"\"Buys stock using cash balance if possible\n",
    "        :param amap: If not enoiugh cash to complete trade, buy as much as possible with current cash\n",
    "        :param buy_date: The date on which to buy the stocks\n",
    "        :param ticker: The stock to purchase\n",
    "        :param quantity_to_buy: The quantity of the stock to purchase (can be a float)\n",
    "        \"\"\"\n",
    "\n",
    "        stock_price = get_stock_price(ticker, buy_date, Time.OPEN)\n",
    "        trade_basis = stock_price * quantity_to_buy  #TODO can add fees here\n",
    "\n",
    "        # Exit if we cannot complete the trade\n",
    "        if trade_basis > self.cash_balance:\n",
    "            if amap:\n",
    "                quantity_to_buy = self.cash_balance/stock_price\n",
    "                trade_basis = stock_price * quantity_to_buy\n",
    "            else:\n",
    "                warnings.warn(\"Not enough cash to execute trade: buy \" + str(quantity_to_buy) + \" \" + ticker)\n",
    "                return\n",
    "\n",
    "        if ticker in self.wash_sale_list:\n",
    "            warnings.warn(\"Cannot buy \" + ticker + \": wash sale violation\")\n",
    "            return\n",
    "\n",
    "        # If we do not currently own the stock, create an entry\n",
    "        if ticker not in list(self.stocks.keys()):\n",
    "            self.stocks[ticker] = Stock(ticker, buy_date)\n",
    "\n",
    "        # Execute the trade\n",
    "        self.stocks[ticker].buy(quantity_to_buy, stock_price)\n",
    "        self.cash_balance -= trade_basis\n",
    "        # print(\"buying \"+ticker+\": \"+str(self.value))\n",
    "\n",
    "    def sell_stock(self, ticker, sell_date, sell_quantity=0, sell_all=False):\n",
    "        \"\"\"Sells stock and adds to cash balance\n",
    "        :param sell_date: The date on which to sell the stocks\n",
    "        :param ticker: The stock to sell\n",
    "        :param sell_quantity: The quantity of the stock to sell (can be a float)\n",
    "        :param sell_all: Optional parameter to sell all stock\n",
    "        \"\"\"\n",
    "        stock_price = get_stock_price(ticker, sell_date, Time.OPEN)\n",
    "        # Ensure we have enough stock to sell\n",
    "        quantity_owned = self.stocks[ticker].quantity\n",
    "        if (sell_quantity > quantity_owned) and not sell_all:\n",
    "            # print(ticker+\" trying to sell\"+str(sell_quantity)+\" but own\"+str(quantity_owned))\n",
    "            return\n",
    "\n",
    "        if sell_all or sell_quantity == quantity_owned:\n",
    "            self.stocks[ticker].sell_all()\n",
    "            self.cash_balance += quantity_owned * stock_price\n",
    "            self.stocks.pop(ticker)\n",
    "\n",
    "            # Update the wash sale list\n",
    "            self.wash_sale_list[ticker] = 0\n",
    "            # print(\"selling \"+ticker+\": \"+str(self.value))\n",
    "            return\n",
    "\n",
    "        # Do the trade\n",
    "        self.stocks[ticker].sell(sell_quantity, stock_price)\n",
    "        self.cash_balance += sell_quantity * stock_price\n",
    "        self.wash_sale_list[ticker] = 0\n",
    "        # print(\"selling \"+ticker+\": \"+str(self.value))\n",
    "\n",
    "    def identify_losers(self, loser_date):\n",
    "        \"\"\"Identifies stocks that have dropped in value more than 5% since they were bought\n",
    "        :returns: List of all stocks that have dropped more than 5%\n",
    "        \"\"\"\n",
    "        #TODO changed identify losers metric\n",
    "        identified_losers = []\n",
    "        for owned_stock in self.stocks.keys():\n",
    "            #if self.stocks[owned_stock].get_change(loser_date) <= -1 * (0.05 * self.value):\n",
    "            quantity = self.stocks[owned_stock].quantity\n",
    "\n",
    "            if (self.stocks[owned_stock].avg_cost * quantity - get_stock_price(owned_stock, loser_date, Time.OPEN) * quantity) > 0.003 * self.value:\n",
    "                if not owned_stock in self.do_not_replace_list:\n",
    "                    identified_losers.append(owned_stock)\n",
    "                #print(str(owned_stock)+\", \" + str(loser_date)+\": \"+str(self.stocks[owned_stock].avg_cost * quantity)+\" - \"+str(get_stock_price(owned_stock, loser_date, Time.OPEN) * quantity)+\" > \"+ str(0.005 * self.value))\n",
    "        return identified_losers\n",
    "\n",
    "    def calculate_diff(self, baseline):\n",
    "        for m in range(0, len(self.closing_prices)):\n",
    "            self.diff.append(self.closing_prices[m] - baseline[m])\n",
    "\n",
    "def scale_portfolio_value(p, ratio, s_s_date):\n",
    "    \"\"\"Returns a new portfolio with quantities of each stock scaled by a specified ratio\"\"\"\n",
    "    new_p = {}\n",
    "    for s in p.stocks:\n",
    "        new_p[s] = Stock(s, s_s_date, p.stocks[s].quantity*ratio)\n",
    "\n",
    "    is_baseline = p.baseline\n",
    "    is_synthetic = p.synthetic\n",
    "    new_port = Portfolio(p.name, s_s_date, p.cash_balance, new_p, baseline=is_baseline, synthetic=is_synthetic)\n",
    "\n",
    "    return new_port\n",
    "\n",
    "\n",
    "def get_normalized_portfolios(p, s_s_date):\n",
    "    \"\"\"Accepts portfolios and returns new portfolios with the same value on the start date\n",
    "    Limitations: All portfolios but the synthetic one can only contain one stock\n",
    "    :param p: The portfolios to normalize (the baseline must be in position 1 and the synthetic portfolio must be marked)\n",
    "    :param s_s_date: The start date on which to normalize the portfolios\n",
    "    \"\"\"\n",
    "    return_ports = []\n",
    "\n",
    "    for port in p:\n",
    "        port_value = port.calculate_value_date(s_s_date)\n",
    "        ratio = 100 / port_value\n",
    "\n",
    "        new_port = scale_portfolio_value(port, ratio, s_s_date)\n",
    "\n",
    "        return_ports.append(new_port)\n",
    "\n",
    "    return return_ports\n",
    "\n",
    "\n",
    "def plot_portfolio(p, sim_end_date, sim_start_date):\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=round((sim_end_date - sim_start_date) / 10)))\n",
    "\n",
    "    for port in p:\n",
    "        days = []\n",
    "        y_price = []\n",
    "        for price in port.price_history:\n",
    "            days.append(price)\n",
    "            y_price.append(port.price_history[price])\n",
    "        plt.plot(days, y_price, label=port.name)\n",
    "\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "    plt.legend(loc='best')\n",
    "    # x1,x2,y1,y2 = plt.axis()\n",
    "    # plt.axis((x1,x2,0,200))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_differences(p, sim_end_date, sim_start_date):\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=round((sim_end_date - sim_start_date) / 10)))\n",
    "\n",
    "    for port in p:\n",
    "        days = []\n",
    "        for price in port.price_history:\n",
    "            days.append(price)\n",
    "        plt.plot(days, port.diff, label=port.name)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def get_correlations(portfolios):\n",
    "    correlations = {}\n",
    "    for p in portfolios:\n",
    "        if p.baseline:\n",
    "            for po in portfolios:\n",
    "                if not po.baseline:\n",
    "                    correlations[p.name+\"x\"+po.name] = po.returns.corr(p.returns)\n",
    "        return correlations\n",
    "\n",
    "\n",
    "def print_correlations(portfolios):\n",
    "    correlations = get_correlations(portfolios)\n",
    "    for correlation in correlations.keys():\n",
    "        print(correlation+\": \"+str(correlations[correlation]))\n",
    "\n",
    "\n",
    "def generate_end_report(portfolios, sim_start_date, sim_end_date):\n",
    "    plot_portfolio(portfolios, sim_end_date, sim_start_date)\n",
    "    for p in portfolios:\n",
    "        p.calculate_diff(portfolios[0].closing_prices)\n",
    "    plot_differences(portfolios, sim_end_date, sim_start_date)\n",
    "    # print_correlations(portfolios)\n",
    "\n",
    "def get_stats(portfolios):\n",
    "    correlations = get_correlations(portfolios)\n",
    "\n",
    "    mse = {}\n",
    "    for p in portfolios:\n",
    "        p.calculate_diff(portfolios[0].closing_prices)\n",
    "    for p in portfolios:\n",
    "        squared_diff = [val**2 for val in p.diff]\n",
    "        mse[p.name] = sum(squared_diff)/len(squared_diff)\n",
    "        if not p.baseline and not p.synthetic:\n",
    "            mse[\"CORR\"] = sum(squared_diff)/len(squared_diff)\n",
    "\n",
    "    mse_percent = {}\n",
    "    baseline = portfolios[0].returns[1:].values\n",
    "    for p in portfolios:\n",
    "        pct_changes = p.returns[1:].values\n",
    "        diff = [pct_changes[h]*100 - baseline[h]*100 for h in range(0, len(pct_changes))]\n",
    "        squared_diff = [val**2 for val in diff]\n",
    "        mse_percent[p.name] = sum(squared_diff)/len(squared_diff)\n",
    "\n",
    "    return {\"Correlation\": correlations, \"MSE\": mse, \"MSE_percent\":mse_percent}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "outputs": [],
   "source": [
    "def model_output_to_portfolio(model_output, output_date):\n",
    "    p = {}\n",
    "    for a_stock in model_output.keys():\n",
    "        try:\n",
    "            p[a_stock] = Stock(a_stock, output_date, model_output[a_stock])\n",
    "        except:\n",
    "            print(\"Excluding: \"+a_stock)\n",
    "    return p\n",
    "\n",
    "\n",
    "def run_simulation(sim_start_date, sim_end_date, portfolios, graph = True):\n",
    "    # Run the simulation\n",
    "    for date in range(sim_start_date, sim_end_date):\n",
    "        # Allow the portfolio to perform start of day updates\n",
    "\n",
    "        for sim_portfolio in portfolios:\n",
    "            sim_portfolio.begin_day(date)\n",
    "            # print(str(date)+\" \" +sim_portfolio.name+\": \"+str(sim_portfolio.value))\n",
    "\n",
    "            if sim_portfolio.replacement:\n",
    "                # Determine which stocks should be tax loss harvested\n",
    "                losers = sim_portfolio.identify_losers(date)\n",
    "\n",
    "                # print(\"losers \"+str(date))\n",
    "                # print(losers)\n",
    "                # print(\"------\")\n",
    "\n",
    "                for losing_stock in losers:\n",
    "                    # Get dictionary of replacement stocks {'Ticker': Quantity}\n",
    "\n",
    "                    replacement_stocks = Portfolio(\"Temp\", date, 0, model_output_to_portfolio(hybrid_learning_replace(losing_stock, date), date))\n",
    "                    ratio = (get_stock_price(losing_stock, date, Time.OPEN)*sim_portfolio.stocks[losing_stock].quantity)/replacement_stocks.value\n",
    "                    replacement_stocks = scale_portfolio_value(replacement_stocks, ratio, date)\n",
    "\n",
    "\n",
    "                    can_do_replacement = True\n",
    "\n",
    "\n",
    "                    for r_stock in replacement_stocks.stocks.keys():\n",
    "                        if r_stock in sim_portfolio.wash_sale_list:\n",
    "                            #print(\"Cannot replace \"+ losing_stock+\" on \"+ str(date) + \"due to wash violation\")\n",
    "                            can_do_replacement = False\n",
    "\n",
    "                    if can_do_replacement:\n",
    "                        # print(\"replacing \"+losing_stock+\" on \"+str(date))\n",
    "                        # Sell the losing stock\n",
    "                        sim_portfolio.sell_stock(losing_stock, date, sell_all=True)\n",
    "\n",
    "                        # Buy the replacement stocks\n",
    "                        s_list = {}\n",
    "                        for buy_stock in replacement_stocks.stocks.keys():\n",
    "                            s_list[buy_stock] = replacement_stocks.stocks[buy_stock].quantity\n",
    "                            sim_portfolio.do_not_replace_list.append(buy_stock)\n",
    "                        rg = ReplacementGroup(s_list, losing_stock)\n",
    "\n",
    "                        for buy_stock in replacement_stocks.stocks.keys():\n",
    "                            sim_portfolio.buy_stock(buy_stock, date, replacement_stocks.stocks[buy_stock].quantity, amap=True)\n",
    "\n",
    "                        sim_portfolio.replacement_groups.append(rg)\n",
    "                        # for s in rg.stock_list:\n",
    "                        #     print(s)\n",
    "\n",
    "                        # for ostock in sim_portfolio.stocks.keys():\n",
    "                        #     print(ostock+\": \"+str(sim_portfolio.stocks[ostock].quantity))\n",
    "                        #\n",
    "                        # print(\"************************\")\n",
    "\n",
    "\n",
    "            # Allow the portfolio to perform end-of-day updates\n",
    "            sim_portfolio.end_day(all_dates[date])\n",
    "        # print()\n",
    "    returns = []\n",
    "\n",
    "    # Inform the portfolio that the simulation has ended\n",
    "    #print()\n",
    "    for portfolio in portfolios:\n",
    "        returns.append(portfolio.end_simulation(sim_start_date, sim_end_date))\n",
    "        # print(portfolio.name+\": \"+str(portfolio.value))\n",
    "\n",
    "    if graph:\n",
    "        generate_end_report(portfolios, sim_start_date, sim_end_date)\n",
    "\n",
    "\n",
    "def simulate_stock(stock, sim_start_date, sim_end_date, tra_end_date, train_num_days, num_principal_components,\n",
    "                   num_pred_stocks, is_sparse, regression_only = False, graph = True):\n",
    "    # Find correlated stock during training period\n",
    "    correlated_stock_ticker = list(corr_list_for_single_stock(stock, tra_end_date, train_num_days).keys())[1]\n",
    "\n",
    "    # Find synthetic stock portfolio during training period\n",
    "    synth_stocks = model_output_to_portfolio(\n",
    "        predict_portfolio(stock, num_principal_components, train_num_days, tra_end_date, num_pred_stocks, is_sparse, regression_only=regression_only),\n",
    "        sim_start_date)\n",
    "\n",
    "    synth_stock_portfolio = Portfolio(\"Synthetic\", sim_start_date, 0, starting_stocks=synth_stocks, synthetic=True)\n",
    "    correlated_stock_portfolio = Portfolio(correlated_stock_ticker, sim_start_date, 0, starting_stocks={\n",
    "        correlated_stock_ticker: Stock(correlated_stock_ticker, sim_start_date, 1)})\n",
    "    baseline_stock_portfolio = Portfolio(stock, sim_start_date, 0,\n",
    "                                         starting_stocks={stock: Stock(stock, sim_start_date, 1)}, baseline=True)\n",
    "\n",
    "    # ensure that the real stock is first in the portfolio\n",
    "    portfolios = get_normalized_portfolios(\n",
    "        [baseline_stock_portfolio, synth_stock_portfolio, correlated_stock_portfolio], sim_start_date)\n",
    "    run_simulation(sim_start_date, sim_end_date, portfolios, graph)\n",
    "    return portfolios"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "outputs": [],
   "source": [
    "# startdate = 90\n",
    "#\n",
    "# #make sure you have 2 separate stock lists, otherwise pass by reference will cause both portfolios to perform the exact same\n",
    "# snp_composition_stocks = model_output_to_portfolio(snp_composition, train_start_date+90)\n",
    "# snp_composition_stocks2 = model_output_to_portfolio(snp_composition, train_start_date+90)\n",
    "# sample = {\"AAPL\": Stock(\"AAPL\", 90, 1), \"COST\": Stock(\"COST\", 90, 1), \"MXL\": Stock(\"MXL\", 90, 1), \"WMT\": Stock(\"WMT\", 90, 1),\n",
    "#           \"KMI\": Stock(\"KMI\", 90, 1), \"MTD\": Stock(\"MTD\", 90, 1), \"MDLZ\": Stock(\"MDLZ\", 90, 1), \"KR\": Stock(\"KR\", 90, 1),\n",
    "#           \"HES\": Stock(\"HES\", 90, 1), \"ORLY\": Stock(\"ORLY\", 90, 1), \"HLT\": Stock(\"HLT\", 90, 1), \"HOLX\": Stock(\"HOLX\", 90, 1),\n",
    "#           \"HON\": Stock(\"HON\", 90, 1), \"OXY\": Stock(\"OXY\", 90, 1), \"OMC\": Stock(\"OMC\", 90, 1), \"LHX\": Stock(\"LHX\", 90, 1)}\n",
    "#\n",
    "# sample2 = {\"AAPL\": Stock(\"AAPL\", 90, 1), \"COST\": Stock(\"COST\", 90, 1), \"MXL\": Stock(\"MXL\", 90, 1), \"WMT\": Stock(\"WMT\", 90, 1),\n",
    "#           \"KMI\": Stock(\"KMI\", 90, 1), \"MTD\": Stock(\"MTD\", 90, 1), \"MDLZ\": Stock(\"MDLZ\", 90, 1), \"KR\": Stock(\"KR\", 90, 1),\n",
    "#           \"HES\": Stock(\"HES\", 90, 1), \"ORLY\": Stock(\"ORLY\", 90, 1), \"HLT\": Stock(\"HLT\", 90, 1), \"HOLX\": Stock(\"HOLX\", 90, 1),\n",
    "#           \"HON\": Stock(\"HON\", 90, 1), \"OXY\": Stock(\"OXY\", 90, 1), \"OMC\": Stock(\"OMC\", 90, 1), \"LHX\": Stock(\"LHX\", 90, 1)}\n",
    "#\n",
    "# snp = Portfolio(\"SNP\", startdate, 0,snp_composition_stocks , baseline=True)\n",
    "# rep = Portfolio(\"Replacer\", startdate, 0, snp_composition_stocks2, replacement=True)\n",
    "#\n",
    "# run_simulation(startdate, 360, [snp, rep], True)\n",
    "\n",
    "\n",
    "#when you replace a stock, group them somehow. disallow this group from being able to be replaced themselves, and add a way to sell them off and buy back the original after 30 days\n",
    "#then, what do you do if another stock you already own is on this list, I guess you'd have to just sell some of it\n",
    "#TODO address that you just need to sell some of this stock"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [553]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_train_days\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     36\u001B[0m     num_train_days \u001B[38;5;241m=\u001B[39m tr_end_date\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 38\u001B[0m stats \u001B[38;5;241m=\u001B[39m get_stats(\u001B[43msimulate_stock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstock_to_sim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_start_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_start_date\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mnum_validation_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtr_end_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_train_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_principal_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_pred_stocks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression_only\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mreg_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m     39\u001B[0m mses\u001B[38;5;241m.\u001B[39mappend(stats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSynthetic\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     40\u001B[0m corr_mses\u001B[38;5;241m.\u001B[39mappend(stats[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCORR\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "Input \u001B[0;32mIn [546]\u001B[0m, in \u001B[0;36msimulate_stock\u001B[0;34m(stock, sim_start_date, sim_end_date, tra_end_date, train_num_days, num_principal_components, num_pred_stocks, is_sparse, regression_only, graph)\u001B[0m\n\u001B[1;32m     87\u001B[0m correlated_stock_ticker \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(corr_list_for_single_stock(stock, tra_end_date, train_num_days)\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# Find synthetic stock portfolio during training period\u001B[39;00m\n\u001B[1;32m     90\u001B[0m synth_stocks \u001B[38;5;241m=\u001B[39m model_output_to_portfolio(\n\u001B[0;32m---> 91\u001B[0m     \u001B[43mpredict_portfolio\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_principal_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_num_days\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtra_end_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_pred_stocks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_sparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregression_only\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     92\u001B[0m     sim_start_date)\n\u001B[1;32m     94\u001B[0m synth_stock_portfolio \u001B[38;5;241m=\u001B[39m Portfolio(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSynthetic\u001B[39m\u001B[38;5;124m\"\u001B[39m, sim_start_date, \u001B[38;5;241m0\u001B[39m, starting_stocks\u001B[38;5;241m=\u001B[39msynth_stocks, synthetic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     95\u001B[0m correlated_stock_portfolio \u001B[38;5;241m=\u001B[39m Portfolio(correlated_stock_ticker, sim_start_date, \u001B[38;5;241m0\u001B[39m, starting_stocks\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m     96\u001B[0m     correlated_stock_ticker: Stock(correlated_stock_ticker, sim_start_date, \u001B[38;5;241m1\u001B[39m)})\n",
      "Input \u001B[0;32mIn [544]\u001B[0m, in \u001B[0;36mpredict_portfolio\u001B[0;34m(pred_stock, n_components, n_days, end_date, n_stocks, is_sparse, regression_only)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_portfolio\u001B[39m(pred_stock, n_components, n_days, end_date, n_stocks, is_sparse, regression_only \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"Constructs a portfolio using the given hyperparameters\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    :param regression_only: Do not perform any PCA\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    :param pred_stock: The stock to predict\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m    :param is_sparse: Whether PCA should be sparse or not\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m     correlation_list \u001B[38;5;241m=\u001B[39m \u001B[43mcorr_list_for_single_stock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_stock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_days\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# Get price history datasets\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m get_datasets(correlation_list, pred_stock, n_stocks, end_date, n_days)\n",
      "Input \u001B[0;32mIn [181]\u001B[0m, in \u001B[0;36mcorr_list_for_single_stock\u001B[0;34m(ticker, end_date, recent_days)\u001B[0m\n\u001B[1;32m     59\u001B[0m correlation_matrix \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(x_labels)):\n\u001B[1;32m     62\u001B[0m     correlation_matrix[x_labels[l]] \u001B[38;5;241m=\u001B[39m ticker_price_history\u001B[38;5;241m.\u001B[39mcorr(\n\u001B[0;32m---> 63\u001B[0m         \u001B[43msptm_price_history\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43ml\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mClose\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpct_change\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39miloc[end_date \u001B[38;5;241m-\u001B[39m recent_days:end_date])\n\u001B[1;32m     64\u001B[0m correlation_matrix \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28msorted\u001B[39m(correlation_matrix\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39moperator\u001B[38;5;241m.\u001B[39mitemgetter(\u001B[38;5;241m1\u001B[39m), reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m correlation_matrix\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/generic.py:10360\u001B[0m, in \u001B[0;36mNDFrame.pct_change\u001B[0;34m(self, periods, fill_method, limit, freq, **kwargs)\u001B[0m\n\u001B[1;32m  10358\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m  10359\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m> 10360\u001B[0m     _data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfillna\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m  10361\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m _data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# needed for mypy\u001B[39;00m\n\u001B[1;32m  10362\u001B[0m     data \u001B[38;5;241m=\u001B[39m _data\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/series.py:4908\u001B[0m, in \u001B[0;36mSeries.fillna\u001B[0;34m(self, value, method, axis, inplace, limit, downcast)\u001B[0m\n\u001B[1;32m   4897\u001B[0m \u001B[38;5;129m@deprecate_nonkeyword_arguments\u001B[39m(version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, allowed_args\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   4898\u001B[0m \u001B[38;5;129m@doc\u001B[39m(NDFrame\u001B[38;5;241m.\u001B[39mfillna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_shared_doc_kwargs)  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[1;32m   4899\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfillna\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4906\u001B[0m     downcast\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   4907\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4908\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfillna\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4909\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4910\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4911\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4912\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4913\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4914\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdowncast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdowncast\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4915\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/generic.py:6437\u001B[0m, in \u001B[0;36mNDFrame.fillna\u001B[0;34m(self, value, method, axis, inplace, limit, downcast)\u001B[0m\n\u001B[1;32m   6433\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39mfillna(method\u001B[38;5;241m=\u001B[39mmethod, limit\u001B[38;5;241m=\u001B[39mlimit)\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m   6435\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m-> 6437\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   6438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   6439\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   6440\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   6441\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   6442\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoerce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   6443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdowncast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdowncast\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   6444\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6445\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6446\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:359\u001B[0m, in \u001B[0;36mBaseBlockManager.interpolate\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minterpolate\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m--> 359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minterpolate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:304\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001B[0m\n\u001B[1;32m    302\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 304\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mNotImplementedError\u001B[39;00m):\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ignore_failures:\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1099\u001B[0m, in \u001B[0;36mBlock.interpolate\u001B[0;34m(self, method, axis, index, inplace, limit, limit_direction, limit_area, fill_value, coerce, downcast, **kwargs)\u001B[0m\n\u001B[1;32m   1096\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01mif\u001B[39;00m inplace \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m   1097\u001B[0m data \u001B[38;5;241m=\u001B[39m cast(np\u001B[38;5;241m.\u001B[39mndarray, data)  \u001B[38;5;66;03m# bc overridden by ExtensionBlock\u001B[39;00m\n\u001B[0;32m-> 1099\u001B[0m \u001B[43mmissing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolate_array_2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1102\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1104\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlimit_direction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit_direction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlimit_area\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit_area\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1109\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m nb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_block_same_class(data)\n\u001B[1;32m   1112\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nb\u001B[38;5;241m.\u001B[39m_maybe_downcast([nb], downcast)\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/missing.py:239\u001B[0m, in \u001B[0;36minterpolate_array_2d\u001B[0;34m(data, method, axis, index, limit, limit_direction, limit_area, fill_value, coerce, downcast, **kwargs)\u001B[0m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fill_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m         \u001B[38;5;66;03m# similar to validate_fillna_kwargs\u001B[39;00m\n\u001B[1;32m    237\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot pass both fill_value and method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 239\u001B[0m     \u001B[43minterpolate_2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlimit_area\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit_area\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    247\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# for mypy\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/missing.py:816\u001B[0m, in \u001B[0;36minterpolate_2d\u001B[0;34m(values, method, axis, limit, limit_area)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;66;03m# _pad_2d and _backfill_2d both modify tvalues inplace\u001B[39;00m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpad\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 816\u001B[0m     \u001B[43m_pad_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    818\u001B[0m     _backfill_2d(tvalues, limit\u001B[38;5;241m=\u001B[39mlimit)\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/missing.py:850\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[0;34m(values, limit, mask)\u001B[0m\n\u001B[1;32m    847\u001B[0m     result, mask \u001B[38;5;241m=\u001B[39m func(values\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi8\u001B[39m\u001B[38;5;124m\"\u001B[39m), limit\u001B[38;5;241m=\u001B[39mlimit, mask\u001B[38;5;241m=\u001B[39mmask)\n\u001B[1;32m    848\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mview(values\u001B[38;5;241m.\u001B[39mdtype), mask\n\u001B[0;32m--> 850\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Finance Research/A-Hybrid-Learning-Approach-to-Generating-Synthetic-Positions-for-Tax-Loss-Harvesting/venv/lib/python3.10/site-packages/pandas/core/missing.py:882\u001B[0m, in \u001B[0;36m_pad_2d\u001B[0;34m(values, limit, mask)\u001B[0m\n\u001B[1;32m    879\u001B[0m mask \u001B[38;5;241m=\u001B[39m _fillna_prep(values, mask)\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(values\u001B[38;5;241m.\u001B[39mshape):\n\u001B[0;32m--> 882\u001B[0m     \u001B[43malgos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_2d_inplace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    884\u001B[0m     \u001B[38;5;66;03m# for test coverage\u001B[39;00m\n\u001B[1;32m    885\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# def simulate_stock(stock: {__eq__},\n",
    "#                    sim_start_date: Any,\n",
    "#                    sim_end_date: {__sub__},\n",
    "#                    tr_end_date: {__sub__},\n",
    "#                    train_num_days: Any,\n",
    "#                    num_principal_components: Any,\n",
    "#                    num_pred_stocks: Any,\n",
    "#                    sparse: Any) -> None\n",
    "#                    graph: bool = True) -> None\n",
    "#simulate_stock('AAPL', test_start_date, test_start_date + 20, train_end_date, 120, 2, 10, False, graph = True)\n",
    "\n",
    "i=0\n",
    "hyperparameters = {}\n",
    "low_mse = 10000000\n",
    "corr_mse = 0\n",
    "for n_principal_components in range(1, 4):\n",
    "    for num_train_days in [0, 30, 60, 90, 150, 180, 360]:\n",
    "        for n_pred_stocks in [2, 3, 5, 10, 15, 25, 50, 100]:\n",
    "            if n_principal_components>=n_pred_stocks:\n",
    "                continue\n",
    "            for sparse in [True, False]:\n",
    "                for reg_only in [True, False]:\n",
    "                    mses = []\n",
    "                    corr_mses = []\n",
    "                    for r in range(0, 100): # repeats a simulation 100 times to get an average measure of the MSE for these hyperparameters over different stocks and time periods\n",
    "                        # tr_end_date should within [train_start_date+num_train_days, train_end_date-num_validation_days] to ensure it does not leak into the test set, even after it is validated\n",
    "                        tr_end_date = random.randint(train_start_date+num_train_days, train_end_date - num_validation_days)\n",
    "\n",
    "                        # validation starts on the soonest day after training is done\n",
    "                        validation_start_date = tr_end_date+1\n",
    "\n",
    "                        num = random.randint(0, len(all_tickers)-1)\n",
    "                        stock_to_sim = list(all_tickers)[num]\n",
    "\n",
    "                        if num_train_days==0:\n",
    "                            num_train_days = tr_end_date-1\n",
    "\n",
    "                        stats = get_stats(simulate_stock(stock_to_sim, validation_start_date, validation_start_date+num_validation_days, tr_end_date, num_train_days, n_principal_components, n_pred_stocks, sparse, regression_only = reg_only, graph=False))\n",
    "                        mses.append(stats['MSE']['Synthetic'])\n",
    "                        corr_mses.append(stats['MSE'][\"CORR\"])\n",
    "\n",
    "                    print(i)\n",
    "                    i+=1\n",
    "\n",
    "                    avg_mse = sum(mses)/100\n",
    "                    avg_corr_mse = sum(corr_mses)/100\n",
    "\n",
    "                    if avg_mse<=low_mse:\n",
    "                        low_mse = avg_mse\n",
    "                        corr_mse = avg_corr_mse\n",
    "                        hyperparameters = {'npca': n_principal_components, 'ntd': num_train_days, 'nps': n_pred_stocks, 'sparse': sparse, 'regression_only': reg_only}\n",
    "                    print(\"round done\")\n",
    "                    print(avg_mse)\n",
    "                    print(avg_corr_mse)\n",
    "                    print(hyperparameters)\n",
    "                    print()\n",
    "\n",
    "print(\"**************************************\")\n",
    "print(low_mse)\n",
    "print(corr_mse)\n",
    "print(hyperparameters)\n",
    "\n",
    "#0.0001232489645044427\n",
    "#{'npca': 2, 'ntd': 30, 'nps': 3, 'sparse': True}\n",
    "# simulate_stock('COST', test_start_date, test_start_date + 20, train_end_date, 30, 2, 3, True, graph = True)\n",
    "\n",
    "# 0.010779939104229553\n",
    "# {'npca': 4, 'ntd': 30, 'nps': 5, 'sparse': False}\n",
    "# simulate_stock(\"COST\", test_start_date, test_start_date+30, train_end_date, 30, 4, 5, True, graph=True)\n",
    "\n",
    "# 46.56410051362909\n",
    "# {'npca': 4, 'ntd': 30, 'nps': 25, 'sparse': False}\n",
    "\n",
    "# 47.28842525584654\n",
    "# {'npca': 7, 'ntd': 90, 'nps': 25, 'sparse': True}\n",
    "\n",
    "# 36.120000133501776\n",
    "# {'npca': 1, 'ntd': 150, 'nps': 15, 'sparse': False}\n",
    "\n",
    "\n",
    "# 22.05078125720328\n",
    "# {'npca': 3, 'ntd': 360, 'nps': 5, 'sparse': False}\n",
    "\n",
    "# 29.38596396938674\n",
    "# 53.247185633481195\n",
    "# {'npca': 1, 'ntd': 90, 'nps': 15, 'sparse': False}\n",
    "\n",
    "# num = random.randint(0, len(all_tickers)-1)\n",
    "# stock_to_sim = list(all_tickers)[num]\n",
    "# sportfolios = simulate_stock(stock_to_sim, test_start_date, test_start_date+30, train_end_date, 90, 2, 15, False, graph=True)\n",
    "# print(get_stats(sportfolios))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#pf.create_returns_tear_sheet(sportfolios[1].returns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}